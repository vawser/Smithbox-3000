// ------------------------------------------------------------------------------
// <auto-generated>
//     This code was generated by a tool.
//
//     Changes to this file may cause incorrect behavior and will be lost if
//     the code is regenerated.
// </auto-generated>
// ------------------------------------------------------------------------------

using System;
using System.Runtime.CompilerServices;
using System.Runtime.InteropServices;
using HexaGen.Runtime;
using System.Numerics;
using Hexa.NET.ImGui;

namespace Hexa.NET.ImPlot
{
	public unsafe partial class ImPlot
	{

		/// <summary>
		/// To be documented.
		/// </summary>
		[MethodImpl(MethodImplOptions.AggressiveInlining)]
		internal static byte ImRemap01Native(byte x, byte x0, byte x1)
		{
			#if NET5_0_OR_GREATER
			return ((delegate* unmanaged[Cdecl]<byte, byte, byte, byte>)funcTable[381])(x, x0, x1);
			#else
			return (byte)((delegate* unmanaged[Cdecl]<byte, byte, byte, byte>)funcTable[381])(x, x0, x1);
			#endif
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		public static byte ImRemap01(byte x, byte x0, byte x1)
		{
			byte ret = ImRemap01Native(x, x0, x1);
			return ret;
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		[MethodImpl(MethodImplOptions.AggressiveInlining)]
		internal static short ImRemap01Native(short x, short x0, short x1)
		{
			#if NET5_0_OR_GREATER
			return ((delegate* unmanaged[Cdecl]<short, short, short, short>)funcTable[382])(x, x0, x1);
			#else
			return (short)((delegate* unmanaged[Cdecl]<short, short, short, short>)funcTable[382])(x, x0, x1);
			#endif
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		public static short ImRemap01(short x, short x0, short x1)
		{
			short ret = ImRemap01Native(x, x0, x1);
			return ret;
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		[MethodImpl(MethodImplOptions.AggressiveInlining)]
		internal static ushort ImRemap01Native(ushort x, ushort x0, ushort x1)
		{
			#if NET5_0_OR_GREATER
			return ((delegate* unmanaged[Cdecl]<ushort, ushort, ushort, ushort>)funcTable[383])(x, x0, x1);
			#else
			return (ushort)((delegate* unmanaged[Cdecl]<ushort, ushort, ushort, ushort>)funcTable[383])(x, x0, x1);
			#endif
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		public static ushort ImRemap01(ushort x, ushort x0, ushort x1)
		{
			ushort ret = ImRemap01Native(x, x0, x1);
			return ret;
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		[MethodImpl(MethodImplOptions.AggressiveInlining)]
		internal static int ImRemap01Native(int x, int x0, int x1)
		{
			#if NET5_0_OR_GREATER
			return ((delegate* unmanaged[Cdecl]<int, int, int, int>)funcTable[384])(x, x0, x1);
			#else
			return (int)((delegate* unmanaged[Cdecl]<int, int, int, int>)funcTable[384])(x, x0, x1);
			#endif
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		public static int ImRemap01(int x, int x0, int x1)
		{
			int ret = ImRemap01Native(x, x0, x1);
			return ret;
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		[MethodImpl(MethodImplOptions.AggressiveInlining)]
		internal static uint ImRemap01Native(uint x, uint x0, uint x1)
		{
			#if NET5_0_OR_GREATER
			return ((delegate* unmanaged[Cdecl]<uint, uint, uint, uint>)funcTable[385])(x, x0, x1);
			#else
			return (uint)((delegate* unmanaged[Cdecl]<uint, uint, uint, uint>)funcTable[385])(x, x0, x1);
			#endif
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		public static uint ImRemap01(uint x, uint x0, uint x1)
		{
			uint ret = ImRemap01Native(x, x0, x1);
			return ret;
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		[MethodImpl(MethodImplOptions.AggressiveInlining)]
		internal static long ImRemap01Native(long x, long x0, long x1)
		{
			#if NET5_0_OR_GREATER
			return ((delegate* unmanaged[Cdecl]<long, long, long, long>)funcTable[386])(x, x0, x1);
			#else
			return (long)((delegate* unmanaged[Cdecl]<long, long, long, long>)funcTable[386])(x, x0, x1);
			#endif
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		public static long ImRemap01(long x, long x0, long x1)
		{
			long ret = ImRemap01Native(x, x0, x1);
			return ret;
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		[MethodImpl(MethodImplOptions.AggressiveInlining)]
		internal static ulong ImRemap01Native(ulong x, ulong x0, ulong x1)
		{
			#if NET5_0_OR_GREATER
			return ((delegate* unmanaged[Cdecl]<ulong, ulong, ulong, ulong>)funcTable[387])(x, x0, x1);
			#else
			return (ulong)((delegate* unmanaged[Cdecl]<ulong, ulong, ulong, ulong>)funcTable[387])(x, x0, x1);
			#endif
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		public static ulong ImRemap01(ulong x, ulong x0, ulong x1)
		{
			ulong ret = ImRemap01Native(x, x0, x1);
			return ret;
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		[MethodImpl(MethodImplOptions.AggressiveInlining)]
		internal static int ImPosModNative(int l, int r)
		{
			#if NET5_0_OR_GREATER
			return ((delegate* unmanaged[Cdecl]<int, int, int>)funcTable[388])(l, r);
			#else
			return (int)((delegate* unmanaged[Cdecl]<int, int, int>)funcTable[388])(l, r);
			#endif
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		public static int ImPosMod(int l, int r)
		{
			int ret = ImPosModNative(l, r);
			return ret;
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		[MethodImpl(MethodImplOptions.AggressiveInlining)]
		internal static byte ImNanNative(double val)
		{
			#if NET5_0_OR_GREATER
			return ((delegate* unmanaged[Cdecl]<double, byte>)funcTable[389])(val);
			#else
			return (byte)((delegate* unmanaged[Cdecl]<double, byte>)funcTable[389])(val);
			#endif
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		public static bool ImNan(double val)
		{
			byte ret = ImNanNative(val);
			return ret != 0;
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		[MethodImpl(MethodImplOptions.AggressiveInlining)]
		internal static byte ImNanOrInfNative(double val)
		{
			#if NET5_0_OR_GREATER
			return ((delegate* unmanaged[Cdecl]<double, byte>)funcTable[390])(val);
			#else
			return (byte)((delegate* unmanaged[Cdecl]<double, byte>)funcTable[390])(val);
			#endif
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		public static bool ImNanOrInf(double val)
		{
			byte ret = ImNanOrInfNative(val);
			return ret != 0;
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		[MethodImpl(MethodImplOptions.AggressiveInlining)]
		internal static double ImConstrainNanNative(double val)
		{
			#if NET5_0_OR_GREATER
			return ((delegate* unmanaged[Cdecl]<double, double>)funcTable[391])(val);
			#else
			return (double)((delegate* unmanaged[Cdecl]<double, double>)funcTable[391])(val);
			#endif
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		public static double ImConstrainNan(double val)
		{
			double ret = ImConstrainNanNative(val);
			return ret;
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		[MethodImpl(MethodImplOptions.AggressiveInlining)]
		internal static double ImConstrainInfNative(double val)
		{
			#if NET5_0_OR_GREATER
			return ((delegate* unmanaged[Cdecl]<double, double>)funcTable[392])(val);
			#else
			return (double)((delegate* unmanaged[Cdecl]<double, double>)funcTable[392])(val);
			#endif
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		public static double ImConstrainInf(double val)
		{
			double ret = ImConstrainInfNative(val);
			return ret;
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		[MethodImpl(MethodImplOptions.AggressiveInlining)]
		internal static double ImConstrainLogNative(double val)
		{
			#if NET5_0_OR_GREATER
			return ((delegate* unmanaged[Cdecl]<double, double>)funcTable[393])(val);
			#else
			return (double)((delegate* unmanaged[Cdecl]<double, double>)funcTable[393])(val);
			#endif
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		public static double ImConstrainLog(double val)
		{
			double ret = ImConstrainLogNative(val);
			return ret;
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		[MethodImpl(MethodImplOptions.AggressiveInlining)]
		internal static double ImConstrainTimeNative(double val)
		{
			#if NET5_0_OR_GREATER
			return ((delegate* unmanaged[Cdecl]<double, double>)funcTable[394])(val);
			#else
			return (double)((delegate* unmanaged[Cdecl]<double, double>)funcTable[394])(val);
			#endif
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		public static double ImConstrainTime(double val)
		{
			double ret = ImConstrainTimeNative(val);
			return ret;
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		[MethodImpl(MethodImplOptions.AggressiveInlining)]
		internal static byte ImAlmostEqualNative(double v1, double v2, int ulp)
		{
			#if NET5_0_OR_GREATER
			return ((delegate* unmanaged[Cdecl]<double, double, int, byte>)funcTable[395])(v1, v2, ulp);
			#else
			return (byte)((delegate* unmanaged[Cdecl]<double, double, int, byte>)funcTable[395])(v1, v2, ulp);
			#endif
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		public static bool ImAlmostEqual(double v1, double v2, int ulp)
		{
			byte ret = ImAlmostEqualNative(v1, v2, ulp);
			return ret != 0;
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		public static bool ImAlmostEqual(double v1, double v2)
		{
			byte ret = ImAlmostEqualNative(v1, v2, (int)(2));
			return ret != 0;
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		[MethodImpl(MethodImplOptions.AggressiveInlining)]
		internal static float ImMinArrayNative(float* values, int count)
		{
			#if NET5_0_OR_GREATER
			return ((delegate* unmanaged[Cdecl]<float*, int, float>)funcTable[396])(values, count);
			#else
			return (float)((delegate* unmanaged[Cdecl]<nint, int, float>)funcTable[396])((nint)values, count);
			#endif
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		public static float ImMinArray(float* values, int count)
		{
			float ret = ImMinArrayNative(values, count);
			return ret;
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		public static float ImMinArray(ref float values, int count)
		{
			fixed (float* pvalues = &values)
			{
				float ret = ImMinArrayNative((float*)pvalues, count);
				return ret;
			}
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		[MethodImpl(MethodImplOptions.AggressiveInlining)]
		internal static double ImMinArrayNative(double* values, int count)
		{
			#if NET5_0_OR_GREATER
			return ((delegate* unmanaged[Cdecl]<double*, int, double>)funcTable[397])(values, count);
			#else
			return (double)((delegate* unmanaged[Cdecl]<nint, int, double>)funcTable[397])((nint)values, count);
			#endif
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		public static double ImMinArray(double* values, int count)
		{
			double ret = ImMinArrayNative(values, count);
			return ret;
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		public static double ImMinArray(ref double values, int count)
		{
			fixed (double* pvalues = &values)
			{
				double ret = ImMinArrayNative((double*)pvalues, count);
				return ret;
			}
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		[MethodImpl(MethodImplOptions.AggressiveInlining)]
		internal static byte ImMinArrayNative(byte* values, int count)
		{
			#if NET5_0_OR_GREATER
			return ((delegate* unmanaged[Cdecl]<byte*, int, byte>)funcTable[398])(values, count);
			#else
			return (byte)((delegate* unmanaged[Cdecl]<nint, int, byte>)funcTable[398])((nint)values, count);
			#endif
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		public static byte ImMinArray(byte* values, int count)
		{
			byte ret = ImMinArrayNative(values, count);
			return ret;
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		public static byte ImMinArray(ref byte values, int count)
		{
			fixed (byte* pvalues = &values)
			{
				byte ret = ImMinArrayNative((byte*)pvalues, count);
				return ret;
			}
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		[MethodImpl(MethodImplOptions.AggressiveInlining)]
		internal static short ImMinArrayNative(short* values, int count)
		{
			#if NET5_0_OR_GREATER
			return ((delegate* unmanaged[Cdecl]<short*, int, short>)funcTable[399])(values, count);
			#else
			return (short)((delegate* unmanaged[Cdecl]<nint, int, short>)funcTable[399])((nint)values, count);
			#endif
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		public static short ImMinArray(short* values, int count)
		{
			short ret = ImMinArrayNative(values, count);
			return ret;
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		public static short ImMinArray(ref short values, int count)
		{
			fixed (short* pvalues = &values)
			{
				short ret = ImMinArrayNative((short*)pvalues, count);
				return ret;
			}
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		[MethodImpl(MethodImplOptions.AggressiveInlining)]
		internal static ushort ImMinArrayNative(ushort* values, int count)
		{
			#if NET5_0_OR_GREATER
			return ((delegate* unmanaged[Cdecl]<ushort*, int, ushort>)funcTable[400])(values, count);
			#else
			return (ushort)((delegate* unmanaged[Cdecl]<nint, int, ushort>)funcTable[400])((nint)values, count);
			#endif
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		public static ushort ImMinArray(ushort* values, int count)
		{
			ushort ret = ImMinArrayNative(values, count);
			return ret;
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		public static ushort ImMinArray(ref ushort values, int count)
		{
			fixed (ushort* pvalues = &values)
			{
				ushort ret = ImMinArrayNative((ushort*)pvalues, count);
				return ret;
			}
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		[MethodImpl(MethodImplOptions.AggressiveInlining)]
		internal static int ImMinArrayNative(int* values, int count)
		{
			#if NET5_0_OR_GREATER
			return ((delegate* unmanaged[Cdecl]<int*, int, int>)funcTable[401])(values, count);
			#else
			return (int)((delegate* unmanaged[Cdecl]<nint, int, int>)funcTable[401])((nint)values, count);
			#endif
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		public static int ImMinArray(int* values, int count)
		{
			int ret = ImMinArrayNative(values, count);
			return ret;
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		public static int ImMinArray(ref int values, int count)
		{
			fixed (int* pvalues = &values)
			{
				int ret = ImMinArrayNative((int*)pvalues, count);
				return ret;
			}
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		[MethodImpl(MethodImplOptions.AggressiveInlining)]
		internal static uint ImMinArrayNative(uint* values, int count)
		{
			#if NET5_0_OR_GREATER
			return ((delegate* unmanaged[Cdecl]<uint*, int, uint>)funcTable[402])(values, count);
			#else
			return (uint)((delegate* unmanaged[Cdecl]<nint, int, uint>)funcTable[402])((nint)values, count);
			#endif
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		public static uint ImMinArray(uint* values, int count)
		{
			uint ret = ImMinArrayNative(values, count);
			return ret;
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		public static uint ImMinArray(ref uint values, int count)
		{
			fixed (uint* pvalues = &values)
			{
				uint ret = ImMinArrayNative((uint*)pvalues, count);
				return ret;
			}
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		[MethodImpl(MethodImplOptions.AggressiveInlining)]
		internal static long ImMinArrayNative(long* values, int count)
		{
			#if NET5_0_OR_GREATER
			return ((delegate* unmanaged[Cdecl]<long*, int, long>)funcTable[403])(values, count);
			#else
			return (long)((delegate* unmanaged[Cdecl]<nint, int, long>)funcTable[403])((nint)values, count);
			#endif
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		public static long ImMinArray(long* values, int count)
		{
			long ret = ImMinArrayNative(values, count);
			return ret;
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		public static long ImMinArray(ref long values, int count)
		{
			fixed (long* pvalues = &values)
			{
				long ret = ImMinArrayNative((long*)pvalues, count);
				return ret;
			}
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		[MethodImpl(MethodImplOptions.AggressiveInlining)]
		internal static ulong ImMinArrayNative(ulong* values, int count)
		{
			#if NET5_0_OR_GREATER
			return ((delegate* unmanaged[Cdecl]<ulong*, int, ulong>)funcTable[404])(values, count);
			#else
			return (ulong)((delegate* unmanaged[Cdecl]<nint, int, ulong>)funcTable[404])((nint)values, count);
			#endif
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		public static ulong ImMinArray(ulong* values, int count)
		{
			ulong ret = ImMinArrayNative(values, count);
			return ret;
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		public static ulong ImMinArray(ref ulong values, int count)
		{
			fixed (ulong* pvalues = &values)
			{
				ulong ret = ImMinArrayNative((ulong*)pvalues, count);
				return ret;
			}
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		[MethodImpl(MethodImplOptions.AggressiveInlining)]
		internal static float ImMaxArrayNative(float* values, int count)
		{
			#if NET5_0_OR_GREATER
			return ((delegate* unmanaged[Cdecl]<float*, int, float>)funcTable[405])(values, count);
			#else
			return (float)((delegate* unmanaged[Cdecl]<nint, int, float>)funcTable[405])((nint)values, count);
			#endif
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		public static float ImMaxArray(float* values, int count)
		{
			float ret = ImMaxArrayNative(values, count);
			return ret;
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		public static float ImMaxArray(ref float values, int count)
		{
			fixed (float* pvalues = &values)
			{
				float ret = ImMaxArrayNative((float*)pvalues, count);
				return ret;
			}
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		[MethodImpl(MethodImplOptions.AggressiveInlining)]
		internal static double ImMaxArrayNative(double* values, int count)
		{
			#if NET5_0_OR_GREATER
			return ((delegate* unmanaged[Cdecl]<double*, int, double>)funcTable[406])(values, count);
			#else
			return (double)((delegate* unmanaged[Cdecl]<nint, int, double>)funcTable[406])((nint)values, count);
			#endif
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		public static double ImMaxArray(double* values, int count)
		{
			double ret = ImMaxArrayNative(values, count);
			return ret;
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		public static double ImMaxArray(ref double values, int count)
		{
			fixed (double* pvalues = &values)
			{
				double ret = ImMaxArrayNative((double*)pvalues, count);
				return ret;
			}
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		[MethodImpl(MethodImplOptions.AggressiveInlining)]
		internal static byte ImMaxArrayNative(byte* values, int count)
		{
			#if NET5_0_OR_GREATER
			return ((delegate* unmanaged[Cdecl]<byte*, int, byte>)funcTable[407])(values, count);
			#else
			return (byte)((delegate* unmanaged[Cdecl]<nint, int, byte>)funcTable[407])((nint)values, count);
			#endif
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		public static byte ImMaxArray(byte* values, int count)
		{
			byte ret = ImMaxArrayNative(values, count);
			return ret;
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		public static byte ImMaxArray(ref byte values, int count)
		{
			fixed (byte* pvalues = &values)
			{
				byte ret = ImMaxArrayNative((byte*)pvalues, count);
				return ret;
			}
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		[MethodImpl(MethodImplOptions.AggressiveInlining)]
		internal static short ImMaxArrayNative(short* values, int count)
		{
			#if NET5_0_OR_GREATER
			return ((delegate* unmanaged[Cdecl]<short*, int, short>)funcTable[408])(values, count);
			#else
			return (short)((delegate* unmanaged[Cdecl]<nint, int, short>)funcTable[408])((nint)values, count);
			#endif
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		public static short ImMaxArray(short* values, int count)
		{
			short ret = ImMaxArrayNative(values, count);
			return ret;
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		public static short ImMaxArray(ref short values, int count)
		{
			fixed (short* pvalues = &values)
			{
				short ret = ImMaxArrayNative((short*)pvalues, count);
				return ret;
			}
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		[MethodImpl(MethodImplOptions.AggressiveInlining)]
		internal static ushort ImMaxArrayNative(ushort* values, int count)
		{
			#if NET5_0_OR_GREATER
			return ((delegate* unmanaged[Cdecl]<ushort*, int, ushort>)funcTable[409])(values, count);
			#else
			return (ushort)((delegate* unmanaged[Cdecl]<nint, int, ushort>)funcTable[409])((nint)values, count);
			#endif
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		public static ushort ImMaxArray(ushort* values, int count)
		{
			ushort ret = ImMaxArrayNative(values, count);
			return ret;
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		public static ushort ImMaxArray(ref ushort values, int count)
		{
			fixed (ushort* pvalues = &values)
			{
				ushort ret = ImMaxArrayNative((ushort*)pvalues, count);
				return ret;
			}
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		[MethodImpl(MethodImplOptions.AggressiveInlining)]
		internal static int ImMaxArrayNative(int* values, int count)
		{
			#if NET5_0_OR_GREATER
			return ((delegate* unmanaged[Cdecl]<int*, int, int>)funcTable[410])(values, count);
			#else
			return (int)((delegate* unmanaged[Cdecl]<nint, int, int>)funcTable[410])((nint)values, count);
			#endif
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		public static int ImMaxArray(int* values, int count)
		{
			int ret = ImMaxArrayNative(values, count);
			return ret;
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		public static int ImMaxArray(ref int values, int count)
		{
			fixed (int* pvalues = &values)
			{
				int ret = ImMaxArrayNative((int*)pvalues, count);
				return ret;
			}
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		[MethodImpl(MethodImplOptions.AggressiveInlining)]
		internal static uint ImMaxArrayNative(uint* values, int count)
		{
			#if NET5_0_OR_GREATER
			return ((delegate* unmanaged[Cdecl]<uint*, int, uint>)funcTable[411])(values, count);
			#else
			return (uint)((delegate* unmanaged[Cdecl]<nint, int, uint>)funcTable[411])((nint)values, count);
			#endif
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		public static uint ImMaxArray(uint* values, int count)
		{
			uint ret = ImMaxArrayNative(values, count);
			return ret;
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		public static uint ImMaxArray(ref uint values, int count)
		{
			fixed (uint* pvalues = &values)
			{
				uint ret = ImMaxArrayNative((uint*)pvalues, count);
				return ret;
			}
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		[MethodImpl(MethodImplOptions.AggressiveInlining)]
		internal static long ImMaxArrayNative(long* values, int count)
		{
			#if NET5_0_OR_GREATER
			return ((delegate* unmanaged[Cdecl]<long*, int, long>)funcTable[412])(values, count);
			#else
			return (long)((delegate* unmanaged[Cdecl]<nint, int, long>)funcTable[412])((nint)values, count);
			#endif
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		public static long ImMaxArray(long* values, int count)
		{
			long ret = ImMaxArrayNative(values, count);
			return ret;
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		public static long ImMaxArray(ref long values, int count)
		{
			fixed (long* pvalues = &values)
			{
				long ret = ImMaxArrayNative((long*)pvalues, count);
				return ret;
			}
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		[MethodImpl(MethodImplOptions.AggressiveInlining)]
		internal static ulong ImMaxArrayNative(ulong* values, int count)
		{
			#if NET5_0_OR_GREATER
			return ((delegate* unmanaged[Cdecl]<ulong*, int, ulong>)funcTable[413])(values, count);
			#else
			return (ulong)((delegate* unmanaged[Cdecl]<nint, int, ulong>)funcTable[413])((nint)values, count);
			#endif
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		public static ulong ImMaxArray(ulong* values, int count)
		{
			ulong ret = ImMaxArrayNative(values, count);
			return ret;
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		public static ulong ImMaxArray(ref ulong values, int count)
		{
			fixed (ulong* pvalues = &values)
			{
				ulong ret = ImMaxArrayNative((ulong*)pvalues, count);
				return ret;
			}
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		[MethodImpl(MethodImplOptions.AggressiveInlining)]
		internal static void ImMinMaxArrayNative(float* values, int count, float* minOut, float* maxOut)
		{
			#if NET5_0_OR_GREATER
			((delegate* unmanaged[Cdecl]<float*, int, float*, float*, void>)funcTable[414])(values, count, minOut, maxOut);
			#else
			((delegate* unmanaged[Cdecl]<nint, int, nint, nint, void>)funcTable[414])((nint)values, count, (nint)minOut, (nint)maxOut);
			#endif
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		public static void ImMinMaxArray(float* values, int count, float* minOut, float* maxOut)
		{
			ImMinMaxArrayNative(values, count, minOut, maxOut);
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		public static void ImMinMaxArray(ref float values, int count, float* minOut, float* maxOut)
		{
			fixed (float* pvalues = &values)
			{
				ImMinMaxArrayNative((float*)pvalues, count, minOut, maxOut);
			}
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		public static void ImMinMaxArray(float* values, int count, ref float minOut, float* maxOut)
		{
			fixed (float* pminOut = &minOut)
			{
				ImMinMaxArrayNative(values, count, (float*)pminOut, maxOut);
			}
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		public static void ImMinMaxArray(ref float values, int count, ref float minOut, float* maxOut)
		{
			fixed (float* pvalues = &values)
			{
				fixed (float* pminOut = &minOut)
				{
					ImMinMaxArrayNative((float*)pvalues, count, (float*)pminOut, maxOut);
				}
			}
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		public static void ImMinMaxArray(float* values, int count, float* minOut, ref float maxOut)
		{
			fixed (float* pmaxOut = &maxOut)
			{
				ImMinMaxArrayNative(values, count, minOut, (float*)pmaxOut);
			}
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		public static void ImMinMaxArray(ref float values, int count, float* minOut, ref float maxOut)
		{
			fixed (float* pvalues = &values)
			{
				fixed (float* pmaxOut = &maxOut)
				{
					ImMinMaxArrayNative((float*)pvalues, count, minOut, (float*)pmaxOut);
				}
			}
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		public static void ImMinMaxArray(float* values, int count, ref float minOut, ref float maxOut)
		{
			fixed (float* pminOut = &minOut)
			{
				fixed (float* pmaxOut = &maxOut)
				{
					ImMinMaxArrayNative(values, count, (float*)pminOut, (float*)pmaxOut);
				}
			}
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		public static void ImMinMaxArray(ref float values, int count, ref float minOut, ref float maxOut)
		{
			fixed (float* pvalues = &values)
			{
				fixed (float* pminOut = &minOut)
				{
					fixed (float* pmaxOut = &maxOut)
					{
						ImMinMaxArrayNative((float*)pvalues, count, (float*)pminOut, (float*)pmaxOut);
					}
				}
			}
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		[MethodImpl(MethodImplOptions.AggressiveInlining)]
		internal static void ImMinMaxArrayNative(double* values, int count, double* minOut, double* maxOut)
		{
			#if NET5_0_OR_GREATER
			((delegate* unmanaged[Cdecl]<double*, int, double*, double*, void>)funcTable[415])(values, count, minOut, maxOut);
			#else
			((delegate* unmanaged[Cdecl]<nint, int, nint, nint, void>)funcTable[415])((nint)values, count, (nint)minOut, (nint)maxOut);
			#endif
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		public static void ImMinMaxArray(double* values, int count, double* minOut, double* maxOut)
		{
			ImMinMaxArrayNative(values, count, minOut, maxOut);
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		public static void ImMinMaxArray(ref double values, int count, double* minOut, double* maxOut)
		{
			fixed (double* pvalues = &values)
			{
				ImMinMaxArrayNative((double*)pvalues, count, minOut, maxOut);
			}
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		public static void ImMinMaxArray(double* values, int count, ref double minOut, double* maxOut)
		{
			fixed (double* pminOut = &minOut)
			{
				ImMinMaxArrayNative(values, count, (double*)pminOut, maxOut);
			}
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		public static void ImMinMaxArray(ref double values, int count, ref double minOut, double* maxOut)
		{
			fixed (double* pvalues = &values)
			{
				fixed (double* pminOut = &minOut)
				{
					ImMinMaxArrayNative((double*)pvalues, count, (double*)pminOut, maxOut);
				}
			}
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		public static void ImMinMaxArray(double* values, int count, double* minOut, ref double maxOut)
		{
			fixed (double* pmaxOut = &maxOut)
			{
				ImMinMaxArrayNative(values, count, minOut, (double*)pmaxOut);
			}
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		public static void ImMinMaxArray(ref double values, int count, double* minOut, ref double maxOut)
		{
			fixed (double* pvalues = &values)
			{
				fixed (double* pmaxOut = &maxOut)
				{
					ImMinMaxArrayNative((double*)pvalues, count, minOut, (double*)pmaxOut);
				}
			}
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		public static void ImMinMaxArray(double* values, int count, ref double minOut, ref double maxOut)
		{
			fixed (double* pminOut = &minOut)
			{
				fixed (double* pmaxOut = &maxOut)
				{
					ImMinMaxArrayNative(values, count, (double*)pminOut, (double*)pmaxOut);
				}
			}
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		public static void ImMinMaxArray(ref double values, int count, ref double minOut, ref double maxOut)
		{
			fixed (double* pvalues = &values)
			{
				fixed (double* pminOut = &minOut)
				{
					fixed (double* pmaxOut = &maxOut)
					{
						ImMinMaxArrayNative((double*)pvalues, count, (double*)pminOut, (double*)pmaxOut);
					}
				}
			}
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		[MethodImpl(MethodImplOptions.AggressiveInlining)]
		internal static void ImMinMaxArrayNative(byte* values, int count, byte* minOut, byte* maxOut)
		{
			#if NET5_0_OR_GREATER
			((delegate* unmanaged[Cdecl]<byte*, int, byte*, byte*, void>)funcTable[416])(values, count, minOut, maxOut);
			#else
			((delegate* unmanaged[Cdecl]<nint, int, nint, nint, void>)funcTable[416])((nint)values, count, (nint)minOut, (nint)maxOut);
			#endif
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		public static void ImMinMaxArray(byte* values, int count, byte* minOut, byte* maxOut)
		{
			ImMinMaxArrayNative(values, count, minOut, maxOut);
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		public static void ImMinMaxArray(ref byte values, int count, byte* minOut, byte* maxOut)
		{
			fixed (byte* pvalues = &values)
			{
				ImMinMaxArrayNative((byte*)pvalues, count, minOut, maxOut);
			}
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		public static void ImMinMaxArray(byte* values, int count, ref byte minOut, byte* maxOut)
		{
			fixed (byte* pminOut = &minOut)
			{
				ImMinMaxArrayNative(values, count, (byte*)pminOut, maxOut);
			}
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		public static void ImMinMaxArray(ref byte values, int count, ref byte minOut, byte* maxOut)
		{
			fixed (byte* pvalues = &values)
			{
				fixed (byte* pminOut = &minOut)
				{
					ImMinMaxArrayNative((byte*)pvalues, count, (byte*)pminOut, maxOut);
				}
			}
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		public static void ImMinMaxArray(byte* values, int count, byte* minOut, ref byte maxOut)
		{
			fixed (byte* pmaxOut = &maxOut)
			{
				ImMinMaxArrayNative(values, count, minOut, (byte*)pmaxOut);
			}
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		public static void ImMinMaxArray(ref byte values, int count, byte* minOut, ref byte maxOut)
		{
			fixed (byte* pvalues = &values)
			{
				fixed (byte* pmaxOut = &maxOut)
				{
					ImMinMaxArrayNative((byte*)pvalues, count, minOut, (byte*)pmaxOut);
				}
			}
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		public static void ImMinMaxArray(byte* values, int count, ref byte minOut, ref byte maxOut)
		{
			fixed (byte* pminOut = &minOut)
			{
				fixed (byte* pmaxOut = &maxOut)
				{
					ImMinMaxArrayNative(values, count, (byte*)pminOut, (byte*)pmaxOut);
				}
			}
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		public static void ImMinMaxArray(ref byte values, int count, ref byte minOut, ref byte maxOut)
		{
			fixed (byte* pvalues = &values)
			{
				fixed (byte* pminOut = &minOut)
				{
					fixed (byte* pmaxOut = &maxOut)
					{
						ImMinMaxArrayNative((byte*)pvalues, count, (byte*)pminOut, (byte*)pmaxOut);
					}
				}
			}
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		[MethodImpl(MethodImplOptions.AggressiveInlining)]
		internal static void ImMinMaxArrayNative(short* values, int count, short* minOut, short* maxOut)
		{
			#if NET5_0_OR_GREATER
			((delegate* unmanaged[Cdecl]<short*, int, short*, short*, void>)funcTable[417])(values, count, minOut, maxOut);
			#else
			((delegate* unmanaged[Cdecl]<nint, int, nint, nint, void>)funcTable[417])((nint)values, count, (nint)minOut, (nint)maxOut);
			#endif
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		public static void ImMinMaxArray(short* values, int count, short* minOut, short* maxOut)
		{
			ImMinMaxArrayNative(values, count, minOut, maxOut);
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		public static void ImMinMaxArray(ref short values, int count, short* minOut, short* maxOut)
		{
			fixed (short* pvalues = &values)
			{
				ImMinMaxArrayNative((short*)pvalues, count, minOut, maxOut);
			}
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		public static void ImMinMaxArray(short* values, int count, ref short minOut, short* maxOut)
		{
			fixed (short* pminOut = &minOut)
			{
				ImMinMaxArrayNative(values, count, (short*)pminOut, maxOut);
			}
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		public static void ImMinMaxArray(ref short values, int count, ref short minOut, short* maxOut)
		{
			fixed (short* pvalues = &values)
			{
				fixed (short* pminOut = &minOut)
				{
					ImMinMaxArrayNative((short*)pvalues, count, (short*)pminOut, maxOut);
				}
			}
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		public static void ImMinMaxArray(short* values, int count, short* minOut, ref short maxOut)
		{
			fixed (short* pmaxOut = &maxOut)
			{
				ImMinMaxArrayNative(values, count, minOut, (short*)pmaxOut);
			}
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		public static void ImMinMaxArray(ref short values, int count, short* minOut, ref short maxOut)
		{
			fixed (short* pvalues = &values)
			{
				fixed (short* pmaxOut = &maxOut)
				{
					ImMinMaxArrayNative((short*)pvalues, count, minOut, (short*)pmaxOut);
				}
			}
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		public static void ImMinMaxArray(short* values, int count, ref short minOut, ref short maxOut)
		{
			fixed (short* pminOut = &minOut)
			{
				fixed (short* pmaxOut = &maxOut)
				{
					ImMinMaxArrayNative(values, count, (short*)pminOut, (short*)pmaxOut);
				}
			}
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		public static void ImMinMaxArray(ref short values, int count, ref short minOut, ref short maxOut)
		{
			fixed (short* pvalues = &values)
			{
				fixed (short* pminOut = &minOut)
				{
					fixed (short* pmaxOut = &maxOut)
					{
						ImMinMaxArrayNative((short*)pvalues, count, (short*)pminOut, (short*)pmaxOut);
					}
				}
			}
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		[MethodImpl(MethodImplOptions.AggressiveInlining)]
		internal static void ImMinMaxArrayNative(ushort* values, int count, ushort* minOut, ushort* maxOut)
		{
			#if NET5_0_OR_GREATER
			((delegate* unmanaged[Cdecl]<ushort*, int, ushort*, ushort*, void>)funcTable[418])(values, count, minOut, maxOut);
			#else
			((delegate* unmanaged[Cdecl]<nint, int, nint, nint, void>)funcTable[418])((nint)values, count, (nint)minOut, (nint)maxOut);
			#endif
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		public static void ImMinMaxArray(ushort* values, int count, ushort* minOut, ushort* maxOut)
		{
			ImMinMaxArrayNative(values, count, minOut, maxOut);
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		public static void ImMinMaxArray(ref ushort values, int count, ushort* minOut, ushort* maxOut)
		{
			fixed (ushort* pvalues = &values)
			{
				ImMinMaxArrayNative((ushort*)pvalues, count, minOut, maxOut);
			}
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		public static void ImMinMaxArray(ushort* values, int count, ref ushort minOut, ushort* maxOut)
		{
			fixed (ushort* pminOut = &minOut)
			{
				ImMinMaxArrayNative(values, count, (ushort*)pminOut, maxOut);
			}
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		public static void ImMinMaxArray(ref ushort values, int count, ref ushort minOut, ushort* maxOut)
		{
			fixed (ushort* pvalues = &values)
			{
				fixed (ushort* pminOut = &minOut)
				{
					ImMinMaxArrayNative((ushort*)pvalues, count, (ushort*)pminOut, maxOut);
				}
			}
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		public static void ImMinMaxArray(ushort* values, int count, ushort* minOut, ref ushort maxOut)
		{
			fixed (ushort* pmaxOut = &maxOut)
			{
				ImMinMaxArrayNative(values, count, minOut, (ushort*)pmaxOut);
			}
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		public static void ImMinMaxArray(ref ushort values, int count, ushort* minOut, ref ushort maxOut)
		{
			fixed (ushort* pvalues = &values)
			{
				fixed (ushort* pmaxOut = &maxOut)
				{
					ImMinMaxArrayNative((ushort*)pvalues, count, minOut, (ushort*)pmaxOut);
				}
			}
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		public static void ImMinMaxArray(ushort* values, int count, ref ushort minOut, ref ushort maxOut)
		{
			fixed (ushort* pminOut = &minOut)
			{
				fixed (ushort* pmaxOut = &maxOut)
				{
					ImMinMaxArrayNative(values, count, (ushort*)pminOut, (ushort*)pmaxOut);
				}
			}
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		public static void ImMinMaxArray(ref ushort values, int count, ref ushort minOut, ref ushort maxOut)
		{
			fixed (ushort* pvalues = &values)
			{
				fixed (ushort* pminOut = &minOut)
				{
					fixed (ushort* pmaxOut = &maxOut)
					{
						ImMinMaxArrayNative((ushort*)pvalues, count, (ushort*)pminOut, (ushort*)pmaxOut);
					}
				}
			}
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		[MethodImpl(MethodImplOptions.AggressiveInlining)]
		internal static void ImMinMaxArrayNative(int* values, int count, int* minOut, int* maxOut)
		{
			#if NET5_0_OR_GREATER
			((delegate* unmanaged[Cdecl]<int*, int, int*, int*, void>)funcTable[419])(values, count, minOut, maxOut);
			#else
			((delegate* unmanaged[Cdecl]<nint, int, nint, nint, void>)funcTable[419])((nint)values, count, (nint)minOut, (nint)maxOut);
			#endif
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		public static void ImMinMaxArray(int* values, int count, int* minOut, int* maxOut)
		{
			ImMinMaxArrayNative(values, count, minOut, maxOut);
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		public static void ImMinMaxArray(ref int values, int count, int* minOut, int* maxOut)
		{
			fixed (int* pvalues = &values)
			{
				ImMinMaxArrayNative((int*)pvalues, count, minOut, maxOut);
			}
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		public static void ImMinMaxArray(int* values, int count, ref int minOut, int* maxOut)
		{
			fixed (int* pminOut = &minOut)
			{
				ImMinMaxArrayNative(values, count, (int*)pminOut, maxOut);
			}
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		public static void ImMinMaxArray(ref int values, int count, ref int minOut, int* maxOut)
		{
			fixed (int* pvalues = &values)
			{
				fixed (int* pminOut = &minOut)
				{
					ImMinMaxArrayNative((int*)pvalues, count, (int*)pminOut, maxOut);
				}
			}
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		public static void ImMinMaxArray(int* values, int count, int* minOut, ref int maxOut)
		{
			fixed (int* pmaxOut = &maxOut)
			{
				ImMinMaxArrayNative(values, count, minOut, (int*)pmaxOut);
			}
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		public static void ImMinMaxArray(ref int values, int count, int* minOut, ref int maxOut)
		{
			fixed (int* pvalues = &values)
			{
				fixed (int* pmaxOut = &maxOut)
				{
					ImMinMaxArrayNative((int*)pvalues, count, minOut, (int*)pmaxOut);
				}
			}
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		public static void ImMinMaxArray(int* values, int count, ref int minOut, ref int maxOut)
		{
			fixed (int* pminOut = &minOut)
			{
				fixed (int* pmaxOut = &maxOut)
				{
					ImMinMaxArrayNative(values, count, (int*)pminOut, (int*)pmaxOut);
				}
			}
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		public static void ImMinMaxArray(ref int values, int count, ref int minOut, ref int maxOut)
		{
			fixed (int* pvalues = &values)
			{
				fixed (int* pminOut = &minOut)
				{
					fixed (int* pmaxOut = &maxOut)
					{
						ImMinMaxArrayNative((int*)pvalues, count, (int*)pminOut, (int*)pmaxOut);
					}
				}
			}
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		[MethodImpl(MethodImplOptions.AggressiveInlining)]
		internal static void ImMinMaxArrayNative(uint* values, int count, uint* minOut, uint* maxOut)
		{
			#if NET5_0_OR_GREATER
			((delegate* unmanaged[Cdecl]<uint*, int, uint*, uint*, void>)funcTable[420])(values, count, minOut, maxOut);
			#else
			((delegate* unmanaged[Cdecl]<nint, int, nint, nint, void>)funcTable[420])((nint)values, count, (nint)minOut, (nint)maxOut);
			#endif
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		public static void ImMinMaxArray(uint* values, int count, uint* minOut, uint* maxOut)
		{
			ImMinMaxArrayNative(values, count, minOut, maxOut);
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		public static void ImMinMaxArray(ref uint values, int count, uint* minOut, uint* maxOut)
		{
			fixed (uint* pvalues = &values)
			{
				ImMinMaxArrayNative((uint*)pvalues, count, minOut, maxOut);
			}
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		public static void ImMinMaxArray(uint* values, int count, ref uint minOut, uint* maxOut)
		{
			fixed (uint* pminOut = &minOut)
			{
				ImMinMaxArrayNative(values, count, (uint*)pminOut, maxOut);
			}
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		public static void ImMinMaxArray(ref uint values, int count, ref uint minOut, uint* maxOut)
		{
			fixed (uint* pvalues = &values)
			{
				fixed (uint* pminOut = &minOut)
				{
					ImMinMaxArrayNative((uint*)pvalues, count, (uint*)pminOut, maxOut);
				}
			}
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		public static void ImMinMaxArray(uint* values, int count, uint* minOut, ref uint maxOut)
		{
			fixed (uint* pmaxOut = &maxOut)
			{
				ImMinMaxArrayNative(values, count, minOut, (uint*)pmaxOut);
			}
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		public static void ImMinMaxArray(ref uint values, int count, uint* minOut, ref uint maxOut)
		{
			fixed (uint* pvalues = &values)
			{
				fixed (uint* pmaxOut = &maxOut)
				{
					ImMinMaxArrayNative((uint*)pvalues, count, minOut, (uint*)pmaxOut);
				}
			}
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		public static void ImMinMaxArray(uint* values, int count, ref uint minOut, ref uint maxOut)
		{
			fixed (uint* pminOut = &minOut)
			{
				fixed (uint* pmaxOut = &maxOut)
				{
					ImMinMaxArrayNative(values, count, (uint*)pminOut, (uint*)pmaxOut);
				}
			}
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		public static void ImMinMaxArray(ref uint values, int count, ref uint minOut, ref uint maxOut)
		{
			fixed (uint* pvalues = &values)
			{
				fixed (uint* pminOut = &minOut)
				{
					fixed (uint* pmaxOut = &maxOut)
					{
						ImMinMaxArrayNative((uint*)pvalues, count, (uint*)pminOut, (uint*)pmaxOut);
					}
				}
			}
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		[MethodImpl(MethodImplOptions.AggressiveInlining)]
		internal static void ImMinMaxArrayNative(long* values, int count, long* minOut, long* maxOut)
		{
			#if NET5_0_OR_GREATER
			((delegate* unmanaged[Cdecl]<long*, int, long*, long*, void>)funcTable[421])(values, count, minOut, maxOut);
			#else
			((delegate* unmanaged[Cdecl]<nint, int, nint, nint, void>)funcTable[421])((nint)values, count, (nint)minOut, (nint)maxOut);
			#endif
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		public static void ImMinMaxArray(long* values, int count, long* minOut, long* maxOut)
		{
			ImMinMaxArrayNative(values, count, minOut, maxOut);
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		public static void ImMinMaxArray(ref long values, int count, long* minOut, long* maxOut)
		{
			fixed (long* pvalues = &values)
			{
				ImMinMaxArrayNative((long*)pvalues, count, minOut, maxOut);
			}
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		public static void ImMinMaxArray(long* values, int count, ref long minOut, long* maxOut)
		{
			fixed (long* pminOut = &minOut)
			{
				ImMinMaxArrayNative(values, count, (long*)pminOut, maxOut);
			}
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		public static void ImMinMaxArray(ref long values, int count, ref long minOut, long* maxOut)
		{
			fixed (long* pvalues = &values)
			{
				fixed (long* pminOut = &minOut)
				{
					ImMinMaxArrayNative((long*)pvalues, count, (long*)pminOut, maxOut);
				}
			}
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		public static void ImMinMaxArray(long* values, int count, long* minOut, ref long maxOut)
		{
			fixed (long* pmaxOut = &maxOut)
			{
				ImMinMaxArrayNative(values, count, minOut, (long*)pmaxOut);
			}
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		public static void ImMinMaxArray(ref long values, int count, long* minOut, ref long maxOut)
		{
			fixed (long* pvalues = &values)
			{
				fixed (long* pmaxOut = &maxOut)
				{
					ImMinMaxArrayNative((long*)pvalues, count, minOut, (long*)pmaxOut);
				}
			}
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		public static void ImMinMaxArray(long* values, int count, ref long minOut, ref long maxOut)
		{
			fixed (long* pminOut = &minOut)
			{
				fixed (long* pmaxOut = &maxOut)
				{
					ImMinMaxArrayNative(values, count, (long*)pminOut, (long*)pmaxOut);
				}
			}
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		public static void ImMinMaxArray(ref long values, int count, ref long minOut, ref long maxOut)
		{
			fixed (long* pvalues = &values)
			{
				fixed (long* pminOut = &minOut)
				{
					fixed (long* pmaxOut = &maxOut)
					{
						ImMinMaxArrayNative((long*)pvalues, count, (long*)pminOut, (long*)pmaxOut);
					}
				}
			}
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		[MethodImpl(MethodImplOptions.AggressiveInlining)]
		internal static void ImMinMaxArrayNative(ulong* values, int count, ulong* minOut, ulong* maxOut)
		{
			#if NET5_0_OR_GREATER
			((delegate* unmanaged[Cdecl]<ulong*, int, ulong*, ulong*, void>)funcTable[422])(values, count, minOut, maxOut);
			#else
			((delegate* unmanaged[Cdecl]<nint, int, nint, nint, void>)funcTable[422])((nint)values, count, (nint)minOut, (nint)maxOut);
			#endif
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		public static void ImMinMaxArray(ulong* values, int count, ulong* minOut, ulong* maxOut)
		{
			ImMinMaxArrayNative(values, count, minOut, maxOut);
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		public static void ImMinMaxArray(ref ulong values, int count, ulong* minOut, ulong* maxOut)
		{
			fixed (ulong* pvalues = &values)
			{
				ImMinMaxArrayNative((ulong*)pvalues, count, minOut, maxOut);
			}
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		public static void ImMinMaxArray(ulong* values, int count, ref ulong minOut, ulong* maxOut)
		{
			fixed (ulong* pminOut = &minOut)
			{
				ImMinMaxArrayNative(values, count, (ulong*)pminOut, maxOut);
			}
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		public static void ImMinMaxArray(ref ulong values, int count, ref ulong minOut, ulong* maxOut)
		{
			fixed (ulong* pvalues = &values)
			{
				fixed (ulong* pminOut = &minOut)
				{
					ImMinMaxArrayNative((ulong*)pvalues, count, (ulong*)pminOut, maxOut);
				}
			}
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		public static void ImMinMaxArray(ulong* values, int count, ulong* minOut, ref ulong maxOut)
		{
			fixed (ulong* pmaxOut = &maxOut)
			{
				ImMinMaxArrayNative(values, count, minOut, (ulong*)pmaxOut);
			}
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		public static void ImMinMaxArray(ref ulong values, int count, ulong* minOut, ref ulong maxOut)
		{
			fixed (ulong* pvalues = &values)
			{
				fixed (ulong* pmaxOut = &maxOut)
				{
					ImMinMaxArrayNative((ulong*)pvalues, count, minOut, (ulong*)pmaxOut);
				}
			}
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		public static void ImMinMaxArray(ulong* values, int count, ref ulong minOut, ref ulong maxOut)
		{
			fixed (ulong* pminOut = &minOut)
			{
				fixed (ulong* pmaxOut = &maxOut)
				{
					ImMinMaxArrayNative(values, count, (ulong*)pminOut, (ulong*)pmaxOut);
				}
			}
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		public static void ImMinMaxArray(ref ulong values, int count, ref ulong minOut, ref ulong maxOut)
		{
			fixed (ulong* pvalues = &values)
			{
				fixed (ulong* pminOut = &minOut)
				{
					fixed (ulong* pmaxOut = &maxOut)
					{
						ImMinMaxArrayNative((ulong*)pvalues, count, (ulong*)pminOut, (ulong*)pmaxOut);
					}
				}
			}
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		[MethodImpl(MethodImplOptions.AggressiveInlining)]
		internal static float ImSumNative(float* values, int count)
		{
			#if NET5_0_OR_GREATER
			return ((delegate* unmanaged[Cdecl]<float*, int, float>)funcTable[423])(values, count);
			#else
			return (float)((delegate* unmanaged[Cdecl]<nint, int, float>)funcTable[423])((nint)values, count);
			#endif
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		public static float ImSum(float* values, int count)
		{
			float ret = ImSumNative(values, count);
			return ret;
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		public static float ImSum(ref float values, int count)
		{
			fixed (float* pvalues = &values)
			{
				float ret = ImSumNative((float*)pvalues, count);
				return ret;
			}
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		[MethodImpl(MethodImplOptions.AggressiveInlining)]
		internal static double ImSumNative(double* values, int count)
		{
			#if NET5_0_OR_GREATER
			return ((delegate* unmanaged[Cdecl]<double*, int, double>)funcTable[424])(values, count);
			#else
			return (double)((delegate* unmanaged[Cdecl]<nint, int, double>)funcTable[424])((nint)values, count);
			#endif
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		public static double ImSum(double* values, int count)
		{
			double ret = ImSumNative(values, count);
			return ret;
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		public static double ImSum(ref double values, int count)
		{
			fixed (double* pvalues = &values)
			{
				double ret = ImSumNative((double*)pvalues, count);
				return ret;
			}
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		[MethodImpl(MethodImplOptions.AggressiveInlining)]
		internal static byte ImSumNative(byte* values, int count)
		{
			#if NET5_0_OR_GREATER
			return ((delegate* unmanaged[Cdecl]<byte*, int, byte>)funcTable[425])(values, count);
			#else
			return (byte)((delegate* unmanaged[Cdecl]<nint, int, byte>)funcTable[425])((nint)values, count);
			#endif
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		public static byte ImSum(byte* values, int count)
		{
			byte ret = ImSumNative(values, count);
			return ret;
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		public static byte ImSum(ref byte values, int count)
		{
			fixed (byte* pvalues = &values)
			{
				byte ret = ImSumNative((byte*)pvalues, count);
				return ret;
			}
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		[MethodImpl(MethodImplOptions.AggressiveInlining)]
		internal static short ImSumNative(short* values, int count)
		{
			#if NET5_0_OR_GREATER
			return ((delegate* unmanaged[Cdecl]<short*, int, short>)funcTable[426])(values, count);
			#else
			return (short)((delegate* unmanaged[Cdecl]<nint, int, short>)funcTable[426])((nint)values, count);
			#endif
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		public static short ImSum(short* values, int count)
		{
			short ret = ImSumNative(values, count);
			return ret;
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		public static short ImSum(ref short values, int count)
		{
			fixed (short* pvalues = &values)
			{
				short ret = ImSumNative((short*)pvalues, count);
				return ret;
			}
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		[MethodImpl(MethodImplOptions.AggressiveInlining)]
		internal static ushort ImSumNative(ushort* values, int count)
		{
			#if NET5_0_OR_GREATER
			return ((delegate* unmanaged[Cdecl]<ushort*, int, ushort>)funcTable[427])(values, count);
			#else
			return (ushort)((delegate* unmanaged[Cdecl]<nint, int, ushort>)funcTable[427])((nint)values, count);
			#endif
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		public static ushort ImSum(ushort* values, int count)
		{
			ushort ret = ImSumNative(values, count);
			return ret;
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		public static ushort ImSum(ref ushort values, int count)
		{
			fixed (ushort* pvalues = &values)
			{
				ushort ret = ImSumNative((ushort*)pvalues, count);
				return ret;
			}
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		[MethodImpl(MethodImplOptions.AggressiveInlining)]
		internal static int ImSumNative(int* values, int count)
		{
			#if NET5_0_OR_GREATER
			return ((delegate* unmanaged[Cdecl]<int*, int, int>)funcTable[428])(values, count);
			#else
			return (int)((delegate* unmanaged[Cdecl]<nint, int, int>)funcTable[428])((nint)values, count);
			#endif
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		public static int ImSum(int* values, int count)
		{
			int ret = ImSumNative(values, count);
			return ret;
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		public static int ImSum(ref int values, int count)
		{
			fixed (int* pvalues = &values)
			{
				int ret = ImSumNative((int*)pvalues, count);
				return ret;
			}
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		[MethodImpl(MethodImplOptions.AggressiveInlining)]
		internal static uint ImSumNative(uint* values, int count)
		{
			#if NET5_0_OR_GREATER
			return ((delegate* unmanaged[Cdecl]<uint*, int, uint>)funcTable[429])(values, count);
			#else
			return (uint)((delegate* unmanaged[Cdecl]<nint, int, uint>)funcTable[429])((nint)values, count);
			#endif
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		public static uint ImSum(uint* values, int count)
		{
			uint ret = ImSumNative(values, count);
			return ret;
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		public static uint ImSum(ref uint values, int count)
		{
			fixed (uint* pvalues = &values)
			{
				uint ret = ImSumNative((uint*)pvalues, count);
				return ret;
			}
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		[MethodImpl(MethodImplOptions.AggressiveInlining)]
		internal static long ImSumNative(long* values, int count)
		{
			#if NET5_0_OR_GREATER
			return ((delegate* unmanaged[Cdecl]<long*, int, long>)funcTable[430])(values, count);
			#else
			return (long)((delegate* unmanaged[Cdecl]<nint, int, long>)funcTable[430])((nint)values, count);
			#endif
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		public static long ImSum(long* values, int count)
		{
			long ret = ImSumNative(values, count);
			return ret;
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		public static long ImSum(ref long values, int count)
		{
			fixed (long* pvalues = &values)
			{
				long ret = ImSumNative((long*)pvalues, count);
				return ret;
			}
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		[MethodImpl(MethodImplOptions.AggressiveInlining)]
		internal static ulong ImSumNative(ulong* values, int count)
		{
			#if NET5_0_OR_GREATER
			return ((delegate* unmanaged[Cdecl]<ulong*, int, ulong>)funcTable[431])(values, count);
			#else
			return (ulong)((delegate* unmanaged[Cdecl]<nint, int, ulong>)funcTable[431])((nint)values, count);
			#endif
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		public static ulong ImSum(ulong* values, int count)
		{
			ulong ret = ImSumNative(values, count);
			return ret;
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		public static ulong ImSum(ref ulong values, int count)
		{
			fixed (ulong* pvalues = &values)
			{
				ulong ret = ImSumNative((ulong*)pvalues, count);
				return ret;
			}
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		[MethodImpl(MethodImplOptions.AggressiveInlining)]
		internal static double ImMeanNative(float* values, int count)
		{
			#if NET5_0_OR_GREATER
			return ((delegate* unmanaged[Cdecl]<float*, int, double>)funcTable[432])(values, count);
			#else
			return (double)((delegate* unmanaged[Cdecl]<nint, int, double>)funcTable[432])((nint)values, count);
			#endif
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		public static double ImMean(float* values, int count)
		{
			double ret = ImMeanNative(values, count);
			return ret;
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		public static double ImMean(ref float values, int count)
		{
			fixed (float* pvalues = &values)
			{
				double ret = ImMeanNative((float*)pvalues, count);
				return ret;
			}
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		[MethodImpl(MethodImplOptions.AggressiveInlining)]
		internal static double ImMeanNative(double* values, int count)
		{
			#if NET5_0_OR_GREATER
			return ((delegate* unmanaged[Cdecl]<double*, int, double>)funcTable[433])(values, count);
			#else
			return (double)((delegate* unmanaged[Cdecl]<nint, int, double>)funcTable[433])((nint)values, count);
			#endif
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		public static double ImMean(double* values, int count)
		{
			double ret = ImMeanNative(values, count);
			return ret;
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		public static double ImMean(ref double values, int count)
		{
			fixed (double* pvalues = &values)
			{
				double ret = ImMeanNative((double*)pvalues, count);
				return ret;
			}
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		[MethodImpl(MethodImplOptions.AggressiveInlining)]
		internal static double ImMeanNative(byte* values, int count)
		{
			#if NET5_0_OR_GREATER
			return ((delegate* unmanaged[Cdecl]<byte*, int, double>)funcTable[434])(values, count);
			#else
			return (double)((delegate* unmanaged[Cdecl]<nint, int, double>)funcTable[434])((nint)values, count);
			#endif
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		public static double ImMean(byte* values, int count)
		{
			double ret = ImMeanNative(values, count);
			return ret;
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		public static double ImMean(ref byte values, int count)
		{
			fixed (byte* pvalues = &values)
			{
				double ret = ImMeanNative((byte*)pvalues, count);
				return ret;
			}
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		[MethodImpl(MethodImplOptions.AggressiveInlining)]
		internal static double ImMeanNative(short* values, int count)
		{
			#if NET5_0_OR_GREATER
			return ((delegate* unmanaged[Cdecl]<short*, int, double>)funcTable[435])(values, count);
			#else
			return (double)((delegate* unmanaged[Cdecl]<nint, int, double>)funcTable[435])((nint)values, count);
			#endif
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		public static double ImMean(short* values, int count)
		{
			double ret = ImMeanNative(values, count);
			return ret;
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		public static double ImMean(ref short values, int count)
		{
			fixed (short* pvalues = &values)
			{
				double ret = ImMeanNative((short*)pvalues, count);
				return ret;
			}
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		[MethodImpl(MethodImplOptions.AggressiveInlining)]
		internal static double ImMeanNative(ushort* values, int count)
		{
			#if NET5_0_OR_GREATER
			return ((delegate* unmanaged[Cdecl]<ushort*, int, double>)funcTable[436])(values, count);
			#else
			return (double)((delegate* unmanaged[Cdecl]<nint, int, double>)funcTable[436])((nint)values, count);
			#endif
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		public static double ImMean(ushort* values, int count)
		{
			double ret = ImMeanNative(values, count);
			return ret;
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		public static double ImMean(ref ushort values, int count)
		{
			fixed (ushort* pvalues = &values)
			{
				double ret = ImMeanNative((ushort*)pvalues, count);
				return ret;
			}
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		[MethodImpl(MethodImplOptions.AggressiveInlining)]
		internal static double ImMeanNative(int* values, int count)
		{
			#if NET5_0_OR_GREATER
			return ((delegate* unmanaged[Cdecl]<int*, int, double>)funcTable[437])(values, count);
			#else
			return (double)((delegate* unmanaged[Cdecl]<nint, int, double>)funcTable[437])((nint)values, count);
			#endif
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		public static double ImMean(int* values, int count)
		{
			double ret = ImMeanNative(values, count);
			return ret;
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		public static double ImMean(ref int values, int count)
		{
			fixed (int* pvalues = &values)
			{
				double ret = ImMeanNative((int*)pvalues, count);
				return ret;
			}
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		[MethodImpl(MethodImplOptions.AggressiveInlining)]
		internal static double ImMeanNative(uint* values, int count)
		{
			#if NET5_0_OR_GREATER
			return ((delegate* unmanaged[Cdecl]<uint*, int, double>)funcTable[438])(values, count);
			#else
			return (double)((delegate* unmanaged[Cdecl]<nint, int, double>)funcTable[438])((nint)values, count);
			#endif
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		public static double ImMean(uint* values, int count)
		{
			double ret = ImMeanNative(values, count);
			return ret;
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		public static double ImMean(ref uint values, int count)
		{
			fixed (uint* pvalues = &values)
			{
				double ret = ImMeanNative((uint*)pvalues, count);
				return ret;
			}
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		[MethodImpl(MethodImplOptions.AggressiveInlining)]
		internal static double ImMeanNative(long* values, int count)
		{
			#if NET5_0_OR_GREATER
			return ((delegate* unmanaged[Cdecl]<long*, int, double>)funcTable[439])(values, count);
			#else
			return (double)((delegate* unmanaged[Cdecl]<nint, int, double>)funcTable[439])((nint)values, count);
			#endif
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		public static double ImMean(long* values, int count)
		{
			double ret = ImMeanNative(values, count);
			return ret;
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		public static double ImMean(ref long values, int count)
		{
			fixed (long* pvalues = &values)
			{
				double ret = ImMeanNative((long*)pvalues, count);
				return ret;
			}
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		[MethodImpl(MethodImplOptions.AggressiveInlining)]
		internal static double ImMeanNative(ulong* values, int count)
		{
			#if NET5_0_OR_GREATER
			return ((delegate* unmanaged[Cdecl]<ulong*, int, double>)funcTable[440])(values, count);
			#else
			return (double)((delegate* unmanaged[Cdecl]<nint, int, double>)funcTable[440])((nint)values, count);
			#endif
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		public static double ImMean(ulong* values, int count)
		{
			double ret = ImMeanNative(values, count);
			return ret;
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		public static double ImMean(ref ulong values, int count)
		{
			fixed (ulong* pvalues = &values)
			{
				double ret = ImMeanNative((ulong*)pvalues, count);
				return ret;
			}
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		[MethodImpl(MethodImplOptions.AggressiveInlining)]
		internal static double ImStdDevNative(float* values, int count)
		{
			#if NET5_0_OR_GREATER
			return ((delegate* unmanaged[Cdecl]<float*, int, double>)funcTable[441])(values, count);
			#else
			return (double)((delegate* unmanaged[Cdecl]<nint, int, double>)funcTable[441])((nint)values, count);
			#endif
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		public static double ImStdDev(float* values, int count)
		{
			double ret = ImStdDevNative(values, count);
			return ret;
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		public static double ImStdDev(ref float values, int count)
		{
			fixed (float* pvalues = &values)
			{
				double ret = ImStdDevNative((float*)pvalues, count);
				return ret;
			}
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		[MethodImpl(MethodImplOptions.AggressiveInlining)]
		internal static double ImStdDevNative(double* values, int count)
		{
			#if NET5_0_OR_GREATER
			return ((delegate* unmanaged[Cdecl]<double*, int, double>)funcTable[442])(values, count);
			#else
			return (double)((delegate* unmanaged[Cdecl]<nint, int, double>)funcTable[442])((nint)values, count);
			#endif
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		public static double ImStdDev(double* values, int count)
		{
			double ret = ImStdDevNative(values, count);
			return ret;
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		public static double ImStdDev(ref double values, int count)
		{
			fixed (double* pvalues = &values)
			{
				double ret = ImStdDevNative((double*)pvalues, count);
				return ret;
			}
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		[MethodImpl(MethodImplOptions.AggressiveInlining)]
		internal static double ImStdDevNative(byte* values, int count)
		{
			#if NET5_0_OR_GREATER
			return ((delegate* unmanaged[Cdecl]<byte*, int, double>)funcTable[443])(values, count);
			#else
			return (double)((delegate* unmanaged[Cdecl]<nint, int, double>)funcTable[443])((nint)values, count);
			#endif
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		public static double ImStdDev(byte* values, int count)
		{
			double ret = ImStdDevNative(values, count);
			return ret;
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		public static double ImStdDev(ref byte values, int count)
		{
			fixed (byte* pvalues = &values)
			{
				double ret = ImStdDevNative((byte*)pvalues, count);
				return ret;
			}
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		[MethodImpl(MethodImplOptions.AggressiveInlining)]
		internal static double ImStdDevNative(short* values, int count)
		{
			#if NET5_0_OR_GREATER
			return ((delegate* unmanaged[Cdecl]<short*, int, double>)funcTable[444])(values, count);
			#else
			return (double)((delegate* unmanaged[Cdecl]<nint, int, double>)funcTable[444])((nint)values, count);
			#endif
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		public static double ImStdDev(short* values, int count)
		{
			double ret = ImStdDevNative(values, count);
			return ret;
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		public static double ImStdDev(ref short values, int count)
		{
			fixed (short* pvalues = &values)
			{
				double ret = ImStdDevNative((short*)pvalues, count);
				return ret;
			}
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		[MethodImpl(MethodImplOptions.AggressiveInlining)]
		internal static double ImStdDevNative(ushort* values, int count)
		{
			#if NET5_0_OR_GREATER
			return ((delegate* unmanaged[Cdecl]<ushort*, int, double>)funcTable[445])(values, count);
			#else
			return (double)((delegate* unmanaged[Cdecl]<nint, int, double>)funcTable[445])((nint)values, count);
			#endif
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		public static double ImStdDev(ushort* values, int count)
		{
			double ret = ImStdDevNative(values, count);
			return ret;
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		public static double ImStdDev(ref ushort values, int count)
		{
			fixed (ushort* pvalues = &values)
			{
				double ret = ImStdDevNative((ushort*)pvalues, count);
				return ret;
			}
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		[MethodImpl(MethodImplOptions.AggressiveInlining)]
		internal static double ImStdDevNative(int* values, int count)
		{
			#if NET5_0_OR_GREATER
			return ((delegate* unmanaged[Cdecl]<int*, int, double>)funcTable[446])(values, count);
			#else
			return (double)((delegate* unmanaged[Cdecl]<nint, int, double>)funcTable[446])((nint)values, count);
			#endif
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		public static double ImStdDev(int* values, int count)
		{
			double ret = ImStdDevNative(values, count);
			return ret;
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		public static double ImStdDev(ref int values, int count)
		{
			fixed (int* pvalues = &values)
			{
				double ret = ImStdDevNative((int*)pvalues, count);
				return ret;
			}
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		[MethodImpl(MethodImplOptions.AggressiveInlining)]
		internal static double ImStdDevNative(uint* values, int count)
		{
			#if NET5_0_OR_GREATER
			return ((delegate* unmanaged[Cdecl]<uint*, int, double>)funcTable[447])(values, count);
			#else
			return (double)((delegate* unmanaged[Cdecl]<nint, int, double>)funcTable[447])((nint)values, count);
			#endif
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		public static double ImStdDev(uint* values, int count)
		{
			double ret = ImStdDevNative(values, count);
			return ret;
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		public static double ImStdDev(ref uint values, int count)
		{
			fixed (uint* pvalues = &values)
			{
				double ret = ImStdDevNative((uint*)pvalues, count);
				return ret;
			}
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		[MethodImpl(MethodImplOptions.AggressiveInlining)]
		internal static double ImStdDevNative(long* values, int count)
		{
			#if NET5_0_OR_GREATER
			return ((delegate* unmanaged[Cdecl]<long*, int, double>)funcTable[448])(values, count);
			#else
			return (double)((delegate* unmanaged[Cdecl]<nint, int, double>)funcTable[448])((nint)values, count);
			#endif
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		public static double ImStdDev(long* values, int count)
		{
			double ret = ImStdDevNative(values, count);
			return ret;
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		public static double ImStdDev(ref long values, int count)
		{
			fixed (long* pvalues = &values)
			{
				double ret = ImStdDevNative((long*)pvalues, count);
				return ret;
			}
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		[MethodImpl(MethodImplOptions.AggressiveInlining)]
		internal static double ImStdDevNative(ulong* values, int count)
		{
			#if NET5_0_OR_GREATER
			return ((delegate* unmanaged[Cdecl]<ulong*, int, double>)funcTable[449])(values, count);
			#else
			return (double)((delegate* unmanaged[Cdecl]<nint, int, double>)funcTable[449])((nint)values, count);
			#endif
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		public static double ImStdDev(ulong* values, int count)
		{
			double ret = ImStdDevNative(values, count);
			return ret;
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		public static double ImStdDev(ref ulong values, int count)
		{
			fixed (ulong* pvalues = &values)
			{
				double ret = ImStdDevNative((ulong*)pvalues, count);
				return ret;
			}
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		[MethodImpl(MethodImplOptions.AggressiveInlining)]
		internal static uint ImMixU32Native(uint a, uint b, uint s)
		{
			#if NET5_0_OR_GREATER
			return ((delegate* unmanaged[Cdecl]<uint, uint, uint, uint>)funcTable[450])(a, b, s);
			#else
			return (uint)((delegate* unmanaged[Cdecl]<uint, uint, uint, uint>)funcTable[450])(a, b, s);
			#endif
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		public static uint ImMixU32(uint a, uint b, uint s)
		{
			uint ret = ImMixU32Native(a, b, s);
			return ret;
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		[MethodImpl(MethodImplOptions.AggressiveInlining)]
		internal static uint ImLerpU32Native(uint* colors, int size, float t)
		{
			#if NET5_0_OR_GREATER
			return ((delegate* unmanaged[Cdecl]<uint*, int, float, uint>)funcTable[451])(colors, size, t);
			#else
			return (uint)((delegate* unmanaged[Cdecl]<nint, int, float, uint>)funcTable[451])((nint)colors, size, t);
			#endif
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		public static uint ImLerpU32(uint* colors, int size, float t)
		{
			uint ret = ImLerpU32Native(colors, size, t);
			return ret;
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		public static uint ImLerpU32(ref uint colors, int size, float t)
		{
			fixed (uint* pcolors = &colors)
			{
				uint ret = ImLerpU32Native((uint*)pcolors, size, t);
				return ret;
			}
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		[MethodImpl(MethodImplOptions.AggressiveInlining)]
		internal static uint ImAlphaU32Native(uint col, float alpha)
		{
			#if NET5_0_OR_GREATER
			return ((delegate* unmanaged[Cdecl]<uint, float, uint>)funcTable[452])(col, alpha);
			#else
			return (uint)((delegate* unmanaged[Cdecl]<uint, float, uint>)funcTable[452])(col, alpha);
			#endif
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		public static uint ImAlphaU32(uint col, float alpha)
		{
			uint ret = ImAlphaU32Native(col, alpha);
			return ret;
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		[MethodImpl(MethodImplOptions.AggressiveInlining)]
		internal static byte ImOverlapsNative(float minA, float maxA, float minB, float maxB)
		{
			#if NET5_0_OR_GREATER
			return ((delegate* unmanaged[Cdecl]<float, float, float, float, byte>)funcTable[453])(minA, maxA, minB, maxB);
			#else
			return (byte)((delegate* unmanaged[Cdecl]<float, float, float, float, byte>)funcTable[453])(minA, maxA, minB, maxB);
			#endif
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		public static bool ImOverlaps(float minA, float maxA, float minB, float maxB)
		{
			byte ret = ImOverlapsNative(minA, maxA, minB, maxB);
			return ret != 0;
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		[MethodImpl(MethodImplOptions.AggressiveInlining)]
		internal static byte ImOverlapsNative(double minA, double maxA, double minB, double maxB)
		{
			#if NET5_0_OR_GREATER
			return ((delegate* unmanaged[Cdecl]<double, double, double, double, byte>)funcTable[454])(minA, maxA, minB, maxB);
			#else
			return (byte)((delegate* unmanaged[Cdecl]<double, double, double, double, byte>)funcTable[454])(minA, maxA, minB, maxB);
			#endif
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		public static bool ImOverlaps(double minA, double maxA, double minB, double maxB)
		{
			byte ret = ImOverlapsNative(minA, maxA, minB, maxB);
			return ret != 0;
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		[MethodImpl(MethodImplOptions.AggressiveInlining)]
		internal static byte ImOverlapsNative(byte minA, byte maxA, byte minB, byte maxB)
		{
			#if NET5_0_OR_GREATER
			return ((delegate* unmanaged[Cdecl]<byte, byte, byte, byte, byte>)funcTable[455])(minA, maxA, minB, maxB);
			#else
			return (byte)((delegate* unmanaged[Cdecl]<byte, byte, byte, byte, byte>)funcTable[455])(minA, maxA, minB, maxB);
			#endif
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		public static bool ImOverlaps(byte minA, byte maxA, byte minB, byte maxB)
		{
			byte ret = ImOverlapsNative(minA, maxA, minB, maxB);
			return ret != 0;
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		[MethodImpl(MethodImplOptions.AggressiveInlining)]
		internal static byte ImOverlapsNative(short minA, short maxA, short minB, short maxB)
		{
			#if NET5_0_OR_GREATER
			return ((delegate* unmanaged[Cdecl]<short, short, short, short, byte>)funcTable[456])(minA, maxA, minB, maxB);
			#else
			return (byte)((delegate* unmanaged[Cdecl]<short, short, short, short, byte>)funcTable[456])(minA, maxA, minB, maxB);
			#endif
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		public static bool ImOverlaps(short minA, short maxA, short minB, short maxB)
		{
			byte ret = ImOverlapsNative(minA, maxA, minB, maxB);
			return ret != 0;
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		[MethodImpl(MethodImplOptions.AggressiveInlining)]
		internal static byte ImOverlapsNative(ushort minA, ushort maxA, ushort minB, ushort maxB)
		{
			#if NET5_0_OR_GREATER
			return ((delegate* unmanaged[Cdecl]<ushort, ushort, ushort, ushort, byte>)funcTable[457])(minA, maxA, minB, maxB);
			#else
			return (byte)((delegate* unmanaged[Cdecl]<ushort, ushort, ushort, ushort, byte>)funcTable[457])(minA, maxA, minB, maxB);
			#endif
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		public static bool ImOverlaps(ushort minA, ushort maxA, ushort minB, ushort maxB)
		{
			byte ret = ImOverlapsNative(minA, maxA, minB, maxB);
			return ret != 0;
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		[MethodImpl(MethodImplOptions.AggressiveInlining)]
		internal static byte ImOverlapsNative(int minA, int maxA, int minB, int maxB)
		{
			#if NET5_0_OR_GREATER
			return ((delegate* unmanaged[Cdecl]<int, int, int, int, byte>)funcTable[458])(minA, maxA, minB, maxB);
			#else
			return (byte)((delegate* unmanaged[Cdecl]<int, int, int, int, byte>)funcTable[458])(minA, maxA, minB, maxB);
			#endif
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		public static bool ImOverlaps(int minA, int maxA, int minB, int maxB)
		{
			byte ret = ImOverlapsNative(minA, maxA, minB, maxB);
			return ret != 0;
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		[MethodImpl(MethodImplOptions.AggressiveInlining)]
		internal static byte ImOverlapsNative(uint minA, uint maxA, uint minB, uint maxB)
		{
			#if NET5_0_OR_GREATER
			return ((delegate* unmanaged[Cdecl]<uint, uint, uint, uint, byte>)funcTable[459])(minA, maxA, minB, maxB);
			#else
			return (byte)((delegate* unmanaged[Cdecl]<uint, uint, uint, uint, byte>)funcTable[459])(minA, maxA, minB, maxB);
			#endif
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		public static bool ImOverlaps(uint minA, uint maxA, uint minB, uint maxB)
		{
			byte ret = ImOverlapsNative(minA, maxA, minB, maxB);
			return ret != 0;
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		[MethodImpl(MethodImplOptions.AggressiveInlining)]
		internal static byte ImOverlapsNative(long minA, long maxA, long minB, long maxB)
		{
			#if NET5_0_OR_GREATER
			return ((delegate* unmanaged[Cdecl]<long, long, long, long, byte>)funcTable[460])(minA, maxA, minB, maxB);
			#else
			return (byte)((delegate* unmanaged[Cdecl]<long, long, long, long, byte>)funcTable[460])(minA, maxA, minB, maxB);
			#endif
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		public static bool ImOverlaps(long minA, long maxA, long minB, long maxB)
		{
			byte ret = ImOverlapsNative(minA, maxA, minB, maxB);
			return ret != 0;
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		[MethodImpl(MethodImplOptions.AggressiveInlining)]
		internal static byte ImOverlapsNative(ulong minA, ulong maxA, ulong minB, ulong maxB)
		{
			#if NET5_0_OR_GREATER
			return ((delegate* unmanaged[Cdecl]<ulong, ulong, ulong, ulong, byte>)funcTable[461])(minA, maxA, minB, maxB);
			#else
			return (byte)((delegate* unmanaged[Cdecl]<ulong, ulong, ulong, ulong, byte>)funcTable[461])(minA, maxA, minB, maxB);
			#endif
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		public static bool ImOverlaps(ulong minA, ulong maxA, ulong minB, ulong maxB)
		{
			byte ret = ImOverlapsNative(minA, maxA, minB, maxB);
			return ret != 0;
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		[MethodImpl(MethodImplOptions.AggressiveInlining)]
		internal static ImPlotDateTimeSpec* ImPlotDateTimeSpecNative()
		{
			#if NET5_0_OR_GREATER
			return ((delegate* unmanaged[Cdecl]<ImPlotDateTimeSpec*>)funcTable[462])();
			#else
			return (ImPlotDateTimeSpec*)((delegate* unmanaged[Cdecl]<nint>)funcTable[462])();
			#endif
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		public static ImPlotDateTimeSpecPtr ImPlotDateTimeSpec()
		{
			ImPlotDateTimeSpecPtr ret = ImPlotDateTimeSpecNative();
			return ret;
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		[MethodImpl(MethodImplOptions.AggressiveInlining)]
		internal static void DestroyNative(ImPlotDateTimeSpec* self)
		{
			#if NET5_0_OR_GREATER
			((delegate* unmanaged[Cdecl]<ImPlotDateTimeSpec*, void>)funcTable[463])(self);
			#else
			((delegate* unmanaged[Cdecl]<nint, void>)funcTable[463])((nint)self);
			#endif
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		public static void Destroy(ImPlotDateTimeSpecPtr self)
		{
			DestroyNative(self);
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		public static void Destroy(ref ImPlotDateTimeSpec self)
		{
			fixed (ImPlotDateTimeSpec* pself = &self)
			{
				DestroyNative((ImPlotDateTimeSpec*)pself);
			}
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		[MethodImpl(MethodImplOptions.AggressiveInlining)]
		internal static ImPlotDateTimeSpec* ImPlotDateTimeSpecNative(ImPlotDateFmt dateFmt, ImPlotTimeFmt timeFmt, byte use24HrClk, byte useIso8601)
		{
			#if NET5_0_OR_GREATER
			return ((delegate* unmanaged[Cdecl]<ImPlotDateFmt, ImPlotTimeFmt, byte, byte, ImPlotDateTimeSpec*>)funcTable[464])(dateFmt, timeFmt, use24HrClk, useIso8601);
			#else
			return (ImPlotDateTimeSpec*)((delegate* unmanaged[Cdecl]<ImPlotDateFmt, ImPlotTimeFmt, byte, byte, nint>)funcTable[464])(dateFmt, timeFmt, use24HrClk, useIso8601);
			#endif
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		public static ImPlotDateTimeSpecPtr ImPlotDateTimeSpec(ImPlotDateFmt dateFmt, ImPlotTimeFmt timeFmt, bool use24HrClk, bool useIso8601)
		{
			ImPlotDateTimeSpecPtr ret = ImPlotDateTimeSpecNative(dateFmt, timeFmt, use24HrClk ? (byte)1 : (byte)0, useIso8601 ? (byte)1 : (byte)0);
			return ret;
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		public static ImPlotDateTimeSpecPtr ImPlotDateTimeSpec(ImPlotDateFmt dateFmt, ImPlotTimeFmt timeFmt, bool use24HrClk)
		{
			ImPlotDateTimeSpecPtr ret = ImPlotDateTimeSpecNative(dateFmt, timeFmt, use24HrClk ? (byte)1 : (byte)0, (byte)(0));
			return ret;
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		public static ImPlotDateTimeSpecPtr ImPlotDateTimeSpec(ImPlotDateFmt dateFmt, ImPlotTimeFmt timeFmt)
		{
			ImPlotDateTimeSpecPtr ret = ImPlotDateTimeSpecNative(dateFmt, timeFmt, (byte)(0), (byte)(0));
			return ret;
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		[MethodImpl(MethodImplOptions.AggressiveInlining)]
		internal static ImPlotTime* ImPlotTimeNative()
		{
			#if NET5_0_OR_GREATER
			return ((delegate* unmanaged[Cdecl]<ImPlotTime*>)funcTable[465])();
			#else
			return (ImPlotTime*)((delegate* unmanaged[Cdecl]<nint>)funcTable[465])();
			#endif
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		public static ImPlotTimePtr ImPlotTime()
		{
			ImPlotTimePtr ret = ImPlotTimeNative();
			return ret;
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		[MethodImpl(MethodImplOptions.AggressiveInlining)]
		internal static void DestroyNative(ImPlotTime* self)
		{
			#if NET5_0_OR_GREATER
			((delegate* unmanaged[Cdecl]<ImPlotTime*, void>)funcTable[466])(self);
			#else
			((delegate* unmanaged[Cdecl]<nint, void>)funcTable[466])((nint)self);
			#endif
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		public static void Destroy(ImPlotTimePtr self)
		{
			DestroyNative(self);
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		public static void Destroy(ref ImPlotTime self)
		{
			fixed (ImPlotTime* pself = &self)
			{
				DestroyNative((ImPlotTime*)pself);
			}
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		[MethodImpl(MethodImplOptions.AggressiveInlining)]
		internal static ImPlotTime* ImPlotTimeNative(long s, int us)
		{
			#if NET5_0_OR_GREATER
			return ((delegate* unmanaged[Cdecl]<long, int, ImPlotTime*>)funcTable[467])(s, us);
			#else
			return (ImPlotTime*)((delegate* unmanaged[Cdecl]<long, int, nint>)funcTable[467])(s, us);
			#endif
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		public static ImPlotTimePtr ImPlotTime(long s, int us)
		{
			ImPlotTimePtr ret = ImPlotTimeNative(s, us);
			return ret;
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		public static ImPlotTimePtr ImPlotTime(long s)
		{
			ImPlotTimePtr ret = ImPlotTimeNative(s, (int)(0));
			return ret;
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		[MethodImpl(MethodImplOptions.AggressiveInlining)]
		internal static void RollOverNative(ImPlotTime* self)
		{
			#if NET5_0_OR_GREATER
			((delegate* unmanaged[Cdecl]<ImPlotTime*, void>)funcTable[468])(self);
			#else
			((delegate* unmanaged[Cdecl]<nint, void>)funcTable[468])((nint)self);
			#endif
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		public static void RollOver(ImPlotTimePtr self)
		{
			RollOverNative(self);
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		public static void RollOver(ref ImPlotTime self)
		{
			fixed (ImPlotTime* pself = &self)
			{
				RollOverNative((ImPlotTime*)pself);
			}
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		[MethodImpl(MethodImplOptions.AggressiveInlining)]
		internal static double ToDoubleNative(ImPlotTime* self)
		{
			#if NET5_0_OR_GREATER
			return ((delegate* unmanaged[Cdecl]<ImPlotTime*, double>)funcTable[469])(self);
			#else
			return (double)((delegate* unmanaged[Cdecl]<nint, double>)funcTable[469])((nint)self);
			#endif
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		public static double ToDouble(ImPlotTimePtr self)
		{
			double ret = ToDoubleNative(self);
			return ret;
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		public static double ToDouble(ref ImPlotTime self)
		{
			fixed (ImPlotTime* pself = &self)
			{
				double ret = ToDoubleNative((ImPlotTime*)pself);
				return ret;
			}
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		[MethodImpl(MethodImplOptions.AggressiveInlining)]
		internal static void FromDoubleNative(ImPlotTime* pOut, double t)
		{
			#if NET5_0_OR_GREATER
			((delegate* unmanaged[Cdecl]<ImPlotTime*, double, void>)funcTable[470])(pOut, t);
			#else
			((delegate* unmanaged[Cdecl]<nint, double, void>)funcTable[470])((nint)pOut, t);
			#endif
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		public static ImPlotTime FromDouble(double t)
		{
			ImPlotTime ret;
			FromDoubleNative(&ret, t);
			return ret;
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		public static void FromDouble(ImPlotTimePtr pOut, double t)
		{
			FromDoubleNative(pOut, t);
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		public static void FromDouble(ref ImPlotTime pOut, double t)
		{
			fixed (ImPlotTime* ppOut = &pOut)
			{
				FromDoubleNative((ImPlotTime*)ppOut, t);
			}
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		[MethodImpl(MethodImplOptions.AggressiveInlining)]
		internal static ImPlotColormapData* ImPlotColormapDataNative()
		{
			#if NET5_0_OR_GREATER
			return ((delegate* unmanaged[Cdecl]<ImPlotColormapData*>)funcTable[471])();
			#else
			return (ImPlotColormapData*)((delegate* unmanaged[Cdecl]<nint>)funcTable[471])();
			#endif
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		public static ImPlotColormapDataPtr ImPlotColormapData()
		{
			ImPlotColormapDataPtr ret = ImPlotColormapDataNative();
			return ret;
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		[MethodImpl(MethodImplOptions.AggressiveInlining)]
		internal static void DestroyNative(ImPlotColormapData* self)
		{
			#if NET5_0_OR_GREATER
			((delegate* unmanaged[Cdecl]<ImPlotColormapData*, void>)funcTable[472])(self);
			#else
			((delegate* unmanaged[Cdecl]<nint, void>)funcTable[472])((nint)self);
			#endif
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		public static void Destroy(ImPlotColormapDataPtr self)
		{
			DestroyNative(self);
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		public static void Destroy(ref ImPlotColormapData self)
		{
			fixed (ImPlotColormapData* pself = &self)
			{
				DestroyNative((ImPlotColormapData*)pself);
			}
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		[MethodImpl(MethodImplOptions.AggressiveInlining)]
		internal static int AppendNative(ImPlotColormapData* self, byte* name, uint* keys, int count, byte qual)
		{
			#if NET5_0_OR_GREATER
			return ((delegate* unmanaged[Cdecl]<ImPlotColormapData*, byte*, uint*, int, byte, int>)funcTable[473])(self, name, keys, count, qual);
			#else
			return (int)((delegate* unmanaged[Cdecl]<nint, nint, nint, int, byte, int>)funcTable[473])((nint)self, (nint)name, (nint)keys, count, qual);
			#endif
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		public static int Append(ImPlotColormapDataPtr self, byte* name, uint* keys, int count, bool qual)
		{
			int ret = AppendNative(self, name, keys, count, qual ? (byte)1 : (byte)0);
			return ret;
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		public static int Append(ref ImPlotColormapData self, byte* name, uint* keys, int count, bool qual)
		{
			fixed (ImPlotColormapData* pself = &self)
			{
				int ret = AppendNative((ImPlotColormapData*)pself, name, keys, count, qual ? (byte)1 : (byte)0);
				return ret;
			}
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		public static int Append(ImPlotColormapDataPtr self, ref byte name, uint* keys, int count, bool qual)
		{
			fixed (byte* pname = &name)
			{
				int ret = AppendNative(self, (byte*)pname, keys, count, qual ? (byte)1 : (byte)0);
				return ret;
			}
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		public static int Append(ImPlotColormapDataPtr self, ReadOnlySpan<byte> name, uint* keys, int count, bool qual)
		{
			fixed (byte* pname = name)
			{
				int ret = AppendNative(self, (byte*)pname, keys, count, qual ? (byte)1 : (byte)0);
				return ret;
			}
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		public static int Append(ImPlotColormapDataPtr self, string name, uint* keys, int count, bool qual)
		{
			byte* pStr0 = null;
			int pStrSize0 = 0;
			if (name != null)
			{
				pStrSize0 = Utils.GetByteCountUTF8(name);
				if (pStrSize0 >= Utils.MaxStackallocSize)
				{
					pStr0 = Utils.Alloc<byte>(pStrSize0 + 1);
				}
				else
				{
					byte* pStrStack0 = stackalloc byte[pStrSize0 + 1];
					pStr0 = pStrStack0;
				}
				int pStrOffset0 = Utils.EncodeStringUTF8(name, pStr0, pStrSize0);
				pStr0[pStrOffset0] = 0;
			}
			int ret = AppendNative(self, pStr0, keys, count, qual ? (byte)1 : (byte)0);
			if (pStrSize0 >= Utils.MaxStackallocSize)
			{
				Utils.Free(pStr0);
			}
			return ret;
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		public static int Append(ref ImPlotColormapData self, ref byte name, uint* keys, int count, bool qual)
		{
			fixed (ImPlotColormapData* pself = &self)
			{
				fixed (byte* pname = &name)
				{
					int ret = AppendNative((ImPlotColormapData*)pself, (byte*)pname, keys, count, qual ? (byte)1 : (byte)0);
					return ret;
				}
			}
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		public static int Append(ref ImPlotColormapData self, ReadOnlySpan<byte> name, uint* keys, int count, bool qual)
		{
			fixed (ImPlotColormapData* pself = &self)
			{
				fixed (byte* pname = name)
				{
					int ret = AppendNative((ImPlotColormapData*)pself, (byte*)pname, keys, count, qual ? (byte)1 : (byte)0);
					return ret;
				}
			}
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		public static int Append(ref ImPlotColormapData self, string name, uint* keys, int count, bool qual)
		{
			fixed (ImPlotColormapData* pself = &self)
			{
				byte* pStr0 = null;
				int pStrSize0 = 0;
				if (name != null)
				{
					pStrSize0 = Utils.GetByteCountUTF8(name);
					if (pStrSize0 >= Utils.MaxStackallocSize)
					{
						pStr0 = Utils.Alloc<byte>(pStrSize0 + 1);
					}
					else
					{
						byte* pStrStack0 = stackalloc byte[pStrSize0 + 1];
						pStr0 = pStrStack0;
					}
					int pStrOffset0 = Utils.EncodeStringUTF8(name, pStr0, pStrSize0);
					pStr0[pStrOffset0] = 0;
				}
				int ret = AppendNative((ImPlotColormapData*)pself, pStr0, keys, count, qual ? (byte)1 : (byte)0);
				if (pStrSize0 >= Utils.MaxStackallocSize)
				{
					Utils.Free(pStr0);
				}
				return ret;
			}
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		public static int Append(ImPlotColormapDataPtr self, byte* name, ref uint keys, int count, bool qual)
		{
			fixed (uint* pkeys = &keys)
			{
				int ret = AppendNative(self, name, (uint*)pkeys, count, qual ? (byte)1 : (byte)0);
				return ret;
			}
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		public static int Append(ref ImPlotColormapData self, byte* name, ref uint keys, int count, bool qual)
		{
			fixed (ImPlotColormapData* pself = &self)
			{
				fixed (uint* pkeys = &keys)
				{
					int ret = AppendNative((ImPlotColormapData*)pself, name, (uint*)pkeys, count, qual ? (byte)1 : (byte)0);
					return ret;
				}
			}
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		public static int Append(ImPlotColormapDataPtr self, ref byte name, ref uint keys, int count, bool qual)
		{
			fixed (byte* pname = &name)
			{
				fixed (uint* pkeys = &keys)
				{
					int ret = AppendNative(self, (byte*)pname, (uint*)pkeys, count, qual ? (byte)1 : (byte)0);
					return ret;
				}
			}
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		public static int Append(ImPlotColormapDataPtr self, ReadOnlySpan<byte> name, ref uint keys, int count, bool qual)
		{
			fixed (byte* pname = name)
			{
				fixed (uint* pkeys = &keys)
				{
					int ret = AppendNative(self, (byte*)pname, (uint*)pkeys, count, qual ? (byte)1 : (byte)0);
					return ret;
				}
			}
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		public static int Append(ImPlotColormapDataPtr self, string name, ref uint keys, int count, bool qual)
		{
			byte* pStr0 = null;
			int pStrSize0 = 0;
			if (name != null)
			{
				pStrSize0 = Utils.GetByteCountUTF8(name);
				if (pStrSize0 >= Utils.MaxStackallocSize)
				{
					pStr0 = Utils.Alloc<byte>(pStrSize0 + 1);
				}
				else
				{
					byte* pStrStack0 = stackalloc byte[pStrSize0 + 1];
					pStr0 = pStrStack0;
				}
				int pStrOffset0 = Utils.EncodeStringUTF8(name, pStr0, pStrSize0);
				pStr0[pStrOffset0] = 0;
			}
			fixed (uint* pkeys = &keys)
			{
				int ret = AppendNative(self, pStr0, (uint*)pkeys, count, qual ? (byte)1 : (byte)0);
				if (pStrSize0 >= Utils.MaxStackallocSize)
				{
					Utils.Free(pStr0);
				}
				return ret;
			}
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		public static int Append(ref ImPlotColormapData self, ref byte name, ref uint keys, int count, bool qual)
		{
			fixed (ImPlotColormapData* pself = &self)
			{
				fixed (byte* pname = &name)
				{
					fixed (uint* pkeys = &keys)
					{
						int ret = AppendNative((ImPlotColormapData*)pself, (byte*)pname, (uint*)pkeys, count, qual ? (byte)1 : (byte)0);
						return ret;
					}
				}
			}
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		public static int Append(ref ImPlotColormapData self, ReadOnlySpan<byte> name, ref uint keys, int count, bool qual)
		{
			fixed (ImPlotColormapData* pself = &self)
			{
				fixed (byte* pname = name)
				{
					fixed (uint* pkeys = &keys)
					{
						int ret = AppendNative((ImPlotColormapData*)pself, (byte*)pname, (uint*)pkeys, count, qual ? (byte)1 : (byte)0);
						return ret;
					}
				}
			}
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		public static int Append(ref ImPlotColormapData self, string name, ref uint keys, int count, bool qual)
		{
			fixed (ImPlotColormapData* pself = &self)
			{
				byte* pStr0 = null;
				int pStrSize0 = 0;
				if (name != null)
				{
					pStrSize0 = Utils.GetByteCountUTF8(name);
					if (pStrSize0 >= Utils.MaxStackallocSize)
					{
						pStr0 = Utils.Alloc<byte>(pStrSize0 + 1);
					}
					else
					{
						byte* pStrStack0 = stackalloc byte[pStrSize0 + 1];
						pStr0 = pStrStack0;
					}
					int pStrOffset0 = Utils.EncodeStringUTF8(name, pStr0, pStrSize0);
					pStr0[pStrOffset0] = 0;
				}
				fixed (uint* pkeys = &keys)
				{
					int ret = AppendNative((ImPlotColormapData*)pself, pStr0, (uint*)pkeys, count, qual ? (byte)1 : (byte)0);
					if (pStrSize0 >= Utils.MaxStackallocSize)
					{
						Utils.Free(pStr0);
					}
					return ret;
				}
			}
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		[MethodImpl(MethodImplOptions.AggressiveInlining)]
		internal static void _AppendTableNative(ImPlotColormapData* self, ImPlotColormap cmap)
		{
			#if NET5_0_OR_GREATER
			((delegate* unmanaged[Cdecl]<ImPlotColormapData*, ImPlotColormap, void>)funcTable[474])(self, cmap);
			#else
			((delegate* unmanaged[Cdecl]<nint, ImPlotColormap, void>)funcTable[474])((nint)self, cmap);
			#endif
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		public static void _AppendTable(ImPlotColormapDataPtr self, ImPlotColormap cmap)
		{
			_AppendTableNative(self, cmap);
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		public static void _AppendTable(ref ImPlotColormapData self, ImPlotColormap cmap)
		{
			fixed (ImPlotColormapData* pself = &self)
			{
				_AppendTableNative((ImPlotColormapData*)pself, cmap);
			}
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		[MethodImpl(MethodImplOptions.AggressiveInlining)]
		internal static void RebuildTablesNative(ImPlotColormapData* self)
		{
			#if NET5_0_OR_GREATER
			((delegate* unmanaged[Cdecl]<ImPlotColormapData*, void>)funcTable[475])(self);
			#else
			((delegate* unmanaged[Cdecl]<nint, void>)funcTable[475])((nint)self);
			#endif
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		public static void RebuildTables(ImPlotColormapDataPtr self)
		{
			RebuildTablesNative(self);
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		public static void RebuildTables(ref ImPlotColormapData self)
		{
			fixed (ImPlotColormapData* pself = &self)
			{
				RebuildTablesNative((ImPlotColormapData*)pself);
			}
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		[MethodImpl(MethodImplOptions.AggressiveInlining)]
		internal static byte IsQualNative(ImPlotColormapData* self, ImPlotColormap cmap)
		{
			#if NET5_0_OR_GREATER
			return ((delegate* unmanaged[Cdecl]<ImPlotColormapData*, ImPlotColormap, byte>)funcTable[476])(self, cmap);
			#else
			return (byte)((delegate* unmanaged[Cdecl]<nint, ImPlotColormap, byte>)funcTable[476])((nint)self, cmap);
			#endif
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		public static bool IsQual(ImPlotColormapDataPtr self, ImPlotColormap cmap)
		{
			byte ret = IsQualNative(self, cmap);
			return ret != 0;
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		public static bool IsQual(ref ImPlotColormapData self, ImPlotColormap cmap)
		{
			fixed (ImPlotColormapData* pself = &self)
			{
				byte ret = IsQualNative((ImPlotColormapData*)pself, cmap);
				return ret != 0;
			}
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		[MethodImpl(MethodImplOptions.AggressiveInlining)]
		internal static byte* GetNameNative(ImPlotColormapData* self, ImPlotColormap cmap)
		{
			#if NET5_0_OR_GREATER
			return ((delegate* unmanaged[Cdecl]<ImPlotColormapData*, ImPlotColormap, byte*>)funcTable[477])(self, cmap);
			#else
			return (byte*)((delegate* unmanaged[Cdecl]<nint, ImPlotColormap, nint>)funcTable[477])((nint)self, cmap);
			#endif
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		public static byte* GetName(ImPlotColormapDataPtr self, ImPlotColormap cmap)
		{
			byte* ret = GetNameNative(self, cmap);
			return ret;
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		public static string GetNameS(ImPlotColormapDataPtr self, ImPlotColormap cmap)
		{
			string ret = Utils.DecodeStringUTF8(GetNameNative(self, cmap));
			return ret;
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		public static byte* GetName(ref ImPlotColormapData self, ImPlotColormap cmap)
		{
			fixed (ImPlotColormapData* pself = &self)
			{
				byte* ret = GetNameNative((ImPlotColormapData*)pself, cmap);
				return ret;
			}
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		public static string GetNameS(ref ImPlotColormapData self, ImPlotColormap cmap)
		{
			fixed (ImPlotColormapData* pself = &self)
			{
				string ret = Utils.DecodeStringUTF8(GetNameNative((ImPlotColormapData*)pself, cmap));
				return ret;
			}
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		[MethodImpl(MethodImplOptions.AggressiveInlining)]
		internal static ImPlotColormap GetIndexNative(ImPlotColormapData* self, byte* name)
		{
			#if NET5_0_OR_GREATER
			return ((delegate* unmanaged[Cdecl]<ImPlotColormapData*, byte*, ImPlotColormap>)funcTable[478])(self, name);
			#else
			return (ImPlotColormap)((delegate* unmanaged[Cdecl]<nint, nint, ImPlotColormap>)funcTable[478])((nint)self, (nint)name);
			#endif
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		public static ImPlotColormap GetIndex(ImPlotColormapDataPtr self, byte* name)
		{
			ImPlotColormap ret = GetIndexNative(self, name);
			return ret;
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		public static ImPlotColormap GetIndex(ref ImPlotColormapData self, byte* name)
		{
			fixed (ImPlotColormapData* pself = &self)
			{
				ImPlotColormap ret = GetIndexNative((ImPlotColormapData*)pself, name);
				return ret;
			}
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		public static ImPlotColormap GetIndex(ImPlotColormapDataPtr self, ref byte name)
		{
			fixed (byte* pname = &name)
			{
				ImPlotColormap ret = GetIndexNative(self, (byte*)pname);
				return ret;
			}
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		public static ImPlotColormap GetIndex(ImPlotColormapDataPtr self, ReadOnlySpan<byte> name)
		{
			fixed (byte* pname = name)
			{
				ImPlotColormap ret = GetIndexNative(self, (byte*)pname);
				return ret;
			}
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		public static ImPlotColormap GetIndex(ImPlotColormapDataPtr self, string name)
		{
			byte* pStr0 = null;
			int pStrSize0 = 0;
			if (name != null)
			{
				pStrSize0 = Utils.GetByteCountUTF8(name);
				if (pStrSize0 >= Utils.MaxStackallocSize)
				{
					pStr0 = Utils.Alloc<byte>(pStrSize0 + 1);
				}
				else
				{
					byte* pStrStack0 = stackalloc byte[pStrSize0 + 1];
					pStr0 = pStrStack0;
				}
				int pStrOffset0 = Utils.EncodeStringUTF8(name, pStr0, pStrSize0);
				pStr0[pStrOffset0] = 0;
			}
			ImPlotColormap ret = GetIndexNative(self, pStr0);
			if (pStrSize0 >= Utils.MaxStackallocSize)
			{
				Utils.Free(pStr0);
			}
			return ret;
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		public static ImPlotColormap GetIndex(ref ImPlotColormapData self, ref byte name)
		{
			fixed (ImPlotColormapData* pself = &self)
			{
				fixed (byte* pname = &name)
				{
					ImPlotColormap ret = GetIndexNative((ImPlotColormapData*)pself, (byte*)pname);
					return ret;
				}
			}
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		public static ImPlotColormap GetIndex(ref ImPlotColormapData self, ReadOnlySpan<byte> name)
		{
			fixed (ImPlotColormapData* pself = &self)
			{
				fixed (byte* pname = name)
				{
					ImPlotColormap ret = GetIndexNative((ImPlotColormapData*)pself, (byte*)pname);
					return ret;
				}
			}
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		public static ImPlotColormap GetIndex(ref ImPlotColormapData self, string name)
		{
			fixed (ImPlotColormapData* pself = &self)
			{
				byte* pStr0 = null;
				int pStrSize0 = 0;
				if (name != null)
				{
					pStrSize0 = Utils.GetByteCountUTF8(name);
					if (pStrSize0 >= Utils.MaxStackallocSize)
					{
						pStr0 = Utils.Alloc<byte>(pStrSize0 + 1);
					}
					else
					{
						byte* pStrStack0 = stackalloc byte[pStrSize0 + 1];
						pStr0 = pStrStack0;
					}
					int pStrOffset0 = Utils.EncodeStringUTF8(name, pStr0, pStrSize0);
					pStr0[pStrOffset0] = 0;
				}
				ImPlotColormap ret = GetIndexNative((ImPlotColormapData*)pself, pStr0);
				if (pStrSize0 >= Utils.MaxStackallocSize)
				{
					Utils.Free(pStr0);
				}
				return ret;
			}
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		[MethodImpl(MethodImplOptions.AggressiveInlining)]
		internal static uint* GetKeysNative(ImPlotColormapData* self, ImPlotColormap cmap)
		{
			#if NET5_0_OR_GREATER
			return ((delegate* unmanaged[Cdecl]<ImPlotColormapData*, ImPlotColormap, uint*>)funcTable[479])(self, cmap);
			#else
			return (uint*)((delegate* unmanaged[Cdecl]<nint, ImPlotColormap, nint>)funcTable[479])((nint)self, cmap);
			#endif
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		public static uint* GetKeys(ImPlotColormapDataPtr self, ImPlotColormap cmap)
		{
			uint* ret = GetKeysNative(self, cmap);
			return ret;
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		public static uint* GetKeys(ref ImPlotColormapData self, ImPlotColormap cmap)
		{
			fixed (ImPlotColormapData* pself = &self)
			{
				uint* ret = GetKeysNative((ImPlotColormapData*)pself, cmap);
				return ret;
			}
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		[MethodImpl(MethodImplOptions.AggressiveInlining)]
		internal static int GetKeyCountNative(ImPlotColormapData* self, ImPlotColormap cmap)
		{
			#if NET5_0_OR_GREATER
			return ((delegate* unmanaged[Cdecl]<ImPlotColormapData*, ImPlotColormap, int>)funcTable[480])(self, cmap);
			#else
			return (int)((delegate* unmanaged[Cdecl]<nint, ImPlotColormap, int>)funcTable[480])((nint)self, cmap);
			#endif
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		public static int GetKeyCount(ImPlotColormapDataPtr self, ImPlotColormap cmap)
		{
			int ret = GetKeyCountNative(self, cmap);
			return ret;
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		public static int GetKeyCount(ref ImPlotColormapData self, ImPlotColormap cmap)
		{
			fixed (ImPlotColormapData* pself = &self)
			{
				int ret = GetKeyCountNative((ImPlotColormapData*)pself, cmap);
				return ret;
			}
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		[MethodImpl(MethodImplOptions.AggressiveInlining)]
		internal static uint GetKeyColorNative(ImPlotColormapData* self, ImPlotColormap cmap, int idx)
		{
			#if NET5_0_OR_GREATER
			return ((delegate* unmanaged[Cdecl]<ImPlotColormapData*, ImPlotColormap, int, uint>)funcTable[481])(self, cmap, idx);
			#else
			return (uint)((delegate* unmanaged[Cdecl]<nint, ImPlotColormap, int, uint>)funcTable[481])((nint)self, cmap, idx);
			#endif
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		public static uint GetKeyColor(ImPlotColormapDataPtr self, ImPlotColormap cmap, int idx)
		{
			uint ret = GetKeyColorNative(self, cmap, idx);
			return ret;
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		public static uint GetKeyColor(ref ImPlotColormapData self, ImPlotColormap cmap, int idx)
		{
			fixed (ImPlotColormapData* pself = &self)
			{
				uint ret = GetKeyColorNative((ImPlotColormapData*)pself, cmap, idx);
				return ret;
			}
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		[MethodImpl(MethodImplOptions.AggressiveInlining)]
		internal static void SetKeyColorNative(ImPlotColormapData* self, ImPlotColormap cmap, int idx, uint value)
		{
			#if NET5_0_OR_GREATER
			((delegate* unmanaged[Cdecl]<ImPlotColormapData*, ImPlotColormap, int, uint, void>)funcTable[482])(self, cmap, idx, value);
			#else
			((delegate* unmanaged[Cdecl]<nint, ImPlotColormap, int, uint, void>)funcTable[482])((nint)self, cmap, idx, value);
			#endif
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		public static void SetKeyColor(ImPlotColormapDataPtr self, ImPlotColormap cmap, int idx, uint value)
		{
			SetKeyColorNative(self, cmap, idx, value);
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		public static void SetKeyColor(ref ImPlotColormapData self, ImPlotColormap cmap, int idx, uint value)
		{
			fixed (ImPlotColormapData* pself = &self)
			{
				SetKeyColorNative((ImPlotColormapData*)pself, cmap, idx, value);
			}
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		[MethodImpl(MethodImplOptions.AggressiveInlining)]
		internal static uint* GetTableNative(ImPlotColormapData* self, ImPlotColormap cmap)
		{
			#if NET5_0_OR_GREATER
			return ((delegate* unmanaged[Cdecl]<ImPlotColormapData*, ImPlotColormap, uint*>)funcTable[483])(self, cmap);
			#else
			return (uint*)((delegate* unmanaged[Cdecl]<nint, ImPlotColormap, nint>)funcTable[483])((nint)self, cmap);
			#endif
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		public static uint* GetTable(ImPlotColormapDataPtr self, ImPlotColormap cmap)
		{
			uint* ret = GetTableNative(self, cmap);
			return ret;
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		public static uint* GetTable(ref ImPlotColormapData self, ImPlotColormap cmap)
		{
			fixed (ImPlotColormapData* pself = &self)
			{
				uint* ret = GetTableNative((ImPlotColormapData*)pself, cmap);
				return ret;
			}
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		[MethodImpl(MethodImplOptions.AggressiveInlining)]
		internal static int GetTableSizeNative(ImPlotColormapData* self, ImPlotColormap cmap)
		{
			#if NET5_0_OR_GREATER
			return ((delegate* unmanaged[Cdecl]<ImPlotColormapData*, ImPlotColormap, int>)funcTable[484])(self, cmap);
			#else
			return (int)((delegate* unmanaged[Cdecl]<nint, ImPlotColormap, int>)funcTable[484])((nint)self, cmap);
			#endif
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		public static int GetTableSize(ImPlotColormapDataPtr self, ImPlotColormap cmap)
		{
			int ret = GetTableSizeNative(self, cmap);
			return ret;
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		public static int GetTableSize(ref ImPlotColormapData self, ImPlotColormap cmap)
		{
			fixed (ImPlotColormapData* pself = &self)
			{
				int ret = GetTableSizeNative((ImPlotColormapData*)pself, cmap);
				return ret;
			}
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		[MethodImpl(MethodImplOptions.AggressiveInlining)]
		internal static uint GetTableColorNative(ImPlotColormapData* self, ImPlotColormap cmap, int idx)
		{
			#if NET5_0_OR_GREATER
			return ((delegate* unmanaged[Cdecl]<ImPlotColormapData*, ImPlotColormap, int, uint>)funcTable[485])(self, cmap, idx);
			#else
			return (uint)((delegate* unmanaged[Cdecl]<nint, ImPlotColormap, int, uint>)funcTable[485])((nint)self, cmap, idx);
			#endif
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		public static uint GetTableColor(ImPlotColormapDataPtr self, ImPlotColormap cmap, int idx)
		{
			uint ret = GetTableColorNative(self, cmap, idx);
			return ret;
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		public static uint GetTableColor(ref ImPlotColormapData self, ImPlotColormap cmap, int idx)
		{
			fixed (ImPlotColormapData* pself = &self)
			{
				uint ret = GetTableColorNative((ImPlotColormapData*)pself, cmap, idx);
				return ret;
			}
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		[MethodImpl(MethodImplOptions.AggressiveInlining)]
		internal static uint LerpTableNative(ImPlotColormapData* self, ImPlotColormap cmap, float t)
		{
			#if NET5_0_OR_GREATER
			return ((delegate* unmanaged[Cdecl]<ImPlotColormapData*, ImPlotColormap, float, uint>)funcTable[486])(self, cmap, t);
			#else
			return (uint)((delegate* unmanaged[Cdecl]<nint, ImPlotColormap, float, uint>)funcTable[486])((nint)self, cmap, t);
			#endif
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		public static uint LerpTable(ImPlotColormapDataPtr self, ImPlotColormap cmap, float t)
		{
			uint ret = LerpTableNative(self, cmap, t);
			return ret;
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		public static uint LerpTable(ref ImPlotColormapData self, ImPlotColormap cmap, float t)
		{
			fixed (ImPlotColormapData* pself = &self)
			{
				uint ret = LerpTableNative((ImPlotColormapData*)pself, cmap, t);
				return ret;
			}
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		[MethodImpl(MethodImplOptions.AggressiveInlining)]
		internal static ImPlotPointError* ImPlotPointErrorNative(double x, double y, double neg, double pos)
		{
			#if NET5_0_OR_GREATER
			return ((delegate* unmanaged[Cdecl]<double, double, double, double, ImPlotPointError*>)funcTable[487])(x, y, neg, pos);
			#else
			return (ImPlotPointError*)((delegate* unmanaged[Cdecl]<double, double, double, double, nint>)funcTable[487])(x, y, neg, pos);
			#endif
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		public static ImPlotPointErrorPtr ImPlotPointError(double x, double y, double neg, double pos)
		{
			ImPlotPointErrorPtr ret = ImPlotPointErrorNative(x, y, neg, pos);
			return ret;
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		[MethodImpl(MethodImplOptions.AggressiveInlining)]
		internal static void DestroyNative(ImPlotPointError* self)
		{
			#if NET5_0_OR_GREATER
			((delegate* unmanaged[Cdecl]<ImPlotPointError*, void>)funcTable[488])(self);
			#else
			((delegate* unmanaged[Cdecl]<nint, void>)funcTable[488])((nint)self);
			#endif
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		public static void Destroy(ImPlotPointErrorPtr self)
		{
			DestroyNative(self);
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		public static void Destroy(ref ImPlotPointError self)
		{
			fixed (ImPlotPointError* pself = &self)
			{
				DestroyNative((ImPlotPointError*)pself);
			}
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		[MethodImpl(MethodImplOptions.AggressiveInlining)]
		internal static ImPlotAnnotation* ImPlotAnnotationNative()
		{
			#if NET5_0_OR_GREATER
			return ((delegate* unmanaged[Cdecl]<ImPlotAnnotation*>)funcTable[489])();
			#else
			return (ImPlotAnnotation*)((delegate* unmanaged[Cdecl]<nint>)funcTable[489])();
			#endif
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		public static ImPlotAnnotationPtr ImPlotAnnotation()
		{
			ImPlotAnnotationPtr ret = ImPlotAnnotationNative();
			return ret;
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		[MethodImpl(MethodImplOptions.AggressiveInlining)]
		internal static void DestroyNative(ImPlotAnnotation* self)
		{
			#if NET5_0_OR_GREATER
			((delegate* unmanaged[Cdecl]<ImPlotAnnotation*, void>)funcTable[490])(self);
			#else
			((delegate* unmanaged[Cdecl]<nint, void>)funcTable[490])((nint)self);
			#endif
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		public static void Destroy(ImPlotAnnotationPtr self)
		{
			DestroyNative(self);
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		public static void Destroy(ref ImPlotAnnotation self)
		{
			fixed (ImPlotAnnotation* pself = &self)
			{
				DestroyNative((ImPlotAnnotation*)pself);
			}
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		[MethodImpl(MethodImplOptions.AggressiveInlining)]
		internal static ImPlotAnnotationCollection* ImPlotAnnotationCollectionNative()
		{
			#if NET5_0_OR_GREATER
			return ((delegate* unmanaged[Cdecl]<ImPlotAnnotationCollection*>)funcTable[491])();
			#else
			return (ImPlotAnnotationCollection*)((delegate* unmanaged[Cdecl]<nint>)funcTable[491])();
			#endif
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		public static ImPlotAnnotationCollectionPtr ImPlotAnnotationCollection()
		{
			ImPlotAnnotationCollectionPtr ret = ImPlotAnnotationCollectionNative();
			return ret;
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		[MethodImpl(MethodImplOptions.AggressiveInlining)]
		internal static void DestroyNative(ImPlotAnnotationCollection* self)
		{
			#if NET5_0_OR_GREATER
			((delegate* unmanaged[Cdecl]<ImPlotAnnotationCollection*, void>)funcTable[492])(self);
			#else
			((delegate* unmanaged[Cdecl]<nint, void>)funcTable[492])((nint)self);
			#endif
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		public static void Destroy(ImPlotAnnotationCollectionPtr self)
		{
			DestroyNative(self);
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		public static void Destroy(ref ImPlotAnnotationCollection self)
		{
			fixed (ImPlotAnnotationCollection* pself = &self)
			{
				DestroyNative((ImPlotAnnotationCollection*)pself);
			}
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		[MethodImpl(MethodImplOptions.AggressiveInlining)]
		internal static void AppendVNative(ImPlotAnnotationCollection* self, Vector2 pos, Vector2 off, uint bg, uint fg, byte clamp, byte* fmt, nuint args)
		{
			#if NET5_0_OR_GREATER
			((delegate* unmanaged[Cdecl]<ImPlotAnnotationCollection*, Vector2, Vector2, uint, uint, byte, byte*, nuint, void>)funcTable[493])(self, pos, off, bg, fg, clamp, fmt, args);
			#else
			((delegate* unmanaged[Cdecl]<nint, Vector2, Vector2, uint, uint, byte, nint, nuint, void>)funcTable[493])((nint)self, pos, off, bg, fg, clamp, (nint)fmt, args);
			#endif
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		public static void AppendV(ImPlotAnnotationCollectionPtr self, Vector2 pos, Vector2 off, uint bg, uint fg, bool clamp, byte* fmt, nuint args)
		{
			AppendVNative(self, pos, off, bg, fg, clamp ? (byte)1 : (byte)0, fmt, args);
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		public static void AppendV(ref ImPlotAnnotationCollection self, Vector2 pos, Vector2 off, uint bg, uint fg, bool clamp, byte* fmt, nuint args)
		{
			fixed (ImPlotAnnotationCollection* pself = &self)
			{
				AppendVNative((ImPlotAnnotationCollection*)pself, pos, off, bg, fg, clamp ? (byte)1 : (byte)0, fmt, args);
			}
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		public static void AppendV(ImPlotAnnotationCollectionPtr self, Vector2 pos, Vector2 off, uint bg, uint fg, bool clamp, ref byte fmt, nuint args)
		{
			fixed (byte* pfmt = &fmt)
			{
				AppendVNative(self, pos, off, bg, fg, clamp ? (byte)1 : (byte)0, (byte*)pfmt, args);
			}
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		public static void AppendV(ImPlotAnnotationCollectionPtr self, Vector2 pos, Vector2 off, uint bg, uint fg, bool clamp, ReadOnlySpan<byte> fmt, nuint args)
		{
			fixed (byte* pfmt = fmt)
			{
				AppendVNative(self, pos, off, bg, fg, clamp ? (byte)1 : (byte)0, (byte*)pfmt, args);
			}
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		public static void AppendV(ImPlotAnnotationCollectionPtr self, Vector2 pos, Vector2 off, uint bg, uint fg, bool clamp, string fmt, nuint args)
		{
			byte* pStr0 = null;
			int pStrSize0 = 0;
			if (fmt != null)
			{
				pStrSize0 = Utils.GetByteCountUTF8(fmt);
				if (pStrSize0 >= Utils.MaxStackallocSize)
				{
					pStr0 = Utils.Alloc<byte>(pStrSize0 + 1);
				}
				else
				{
					byte* pStrStack0 = stackalloc byte[pStrSize0 + 1];
					pStr0 = pStrStack0;
				}
				int pStrOffset0 = Utils.EncodeStringUTF8(fmt, pStr0, pStrSize0);
				pStr0[pStrOffset0] = 0;
			}
			AppendVNative(self, pos, off, bg, fg, clamp ? (byte)1 : (byte)0, pStr0, args);
			if (pStrSize0 >= Utils.MaxStackallocSize)
			{
				Utils.Free(pStr0);
			}
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		public static void AppendV(ref ImPlotAnnotationCollection self, Vector2 pos, Vector2 off, uint bg, uint fg, bool clamp, ref byte fmt, nuint args)
		{
			fixed (ImPlotAnnotationCollection* pself = &self)
			{
				fixed (byte* pfmt = &fmt)
				{
					AppendVNative((ImPlotAnnotationCollection*)pself, pos, off, bg, fg, clamp ? (byte)1 : (byte)0, (byte*)pfmt, args);
				}
			}
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		public static void AppendV(ref ImPlotAnnotationCollection self, Vector2 pos, Vector2 off, uint bg, uint fg, bool clamp, ReadOnlySpan<byte> fmt, nuint args)
		{
			fixed (ImPlotAnnotationCollection* pself = &self)
			{
				fixed (byte* pfmt = fmt)
				{
					AppendVNative((ImPlotAnnotationCollection*)pself, pos, off, bg, fg, clamp ? (byte)1 : (byte)0, (byte*)pfmt, args);
				}
			}
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		public static void AppendV(ref ImPlotAnnotationCollection self, Vector2 pos, Vector2 off, uint bg, uint fg, bool clamp, string fmt, nuint args)
		{
			fixed (ImPlotAnnotationCollection* pself = &self)
			{
				byte* pStr0 = null;
				int pStrSize0 = 0;
				if (fmt != null)
				{
					pStrSize0 = Utils.GetByteCountUTF8(fmt);
					if (pStrSize0 >= Utils.MaxStackallocSize)
					{
						pStr0 = Utils.Alloc<byte>(pStrSize0 + 1);
					}
					else
					{
						byte* pStrStack0 = stackalloc byte[pStrSize0 + 1];
						pStr0 = pStrStack0;
					}
					int pStrOffset0 = Utils.EncodeStringUTF8(fmt, pStr0, pStrSize0);
					pStr0[pStrOffset0] = 0;
				}
				AppendVNative((ImPlotAnnotationCollection*)pself, pos, off, bg, fg, clamp ? (byte)1 : (byte)0, pStr0, args);
				if (pStrSize0 >= Utils.MaxStackallocSize)
				{
					Utils.Free(pStr0);
				}
			}
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		[MethodImpl(MethodImplOptions.AggressiveInlining)]
		internal static void AppendNative(ImPlotAnnotationCollection* self, Vector2 pos, Vector2 off, uint bg, uint fg, byte clamp, byte* fmt)
		{
			#if NET5_0_OR_GREATER
			((delegate* unmanaged[Cdecl]<ImPlotAnnotationCollection*, Vector2, Vector2, uint, uint, byte, byte*, void>)funcTable[494])(self, pos, off, bg, fg, clamp, fmt);
			#else
			((delegate* unmanaged[Cdecl]<nint, Vector2, Vector2, uint, uint, byte, nint, void>)funcTable[494])((nint)self, pos, off, bg, fg, clamp, (nint)fmt);
			#endif
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		public static void Append(ImPlotAnnotationCollectionPtr self, Vector2 pos, Vector2 off, uint bg, uint fg, bool clamp, byte* fmt)
		{
			AppendNative(self, pos, off, bg, fg, clamp ? (byte)1 : (byte)0, fmt);
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		public static void Append(ref ImPlotAnnotationCollection self, Vector2 pos, Vector2 off, uint bg, uint fg, bool clamp, byte* fmt)
		{
			fixed (ImPlotAnnotationCollection* pself = &self)
			{
				AppendNative((ImPlotAnnotationCollection*)pself, pos, off, bg, fg, clamp ? (byte)1 : (byte)0, fmt);
			}
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		public static void Append(ImPlotAnnotationCollectionPtr self, Vector2 pos, Vector2 off, uint bg, uint fg, bool clamp, ref byte fmt)
		{
			fixed (byte* pfmt = &fmt)
			{
				AppendNative(self, pos, off, bg, fg, clamp ? (byte)1 : (byte)0, (byte*)pfmt);
			}
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		public static void Append(ImPlotAnnotationCollectionPtr self, Vector2 pos, Vector2 off, uint bg, uint fg, bool clamp, ReadOnlySpan<byte> fmt)
		{
			fixed (byte* pfmt = fmt)
			{
				AppendNative(self, pos, off, bg, fg, clamp ? (byte)1 : (byte)0, (byte*)pfmt);
			}
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		public static void Append(ImPlotAnnotationCollectionPtr self, Vector2 pos, Vector2 off, uint bg, uint fg, bool clamp, string fmt)
		{
			byte* pStr0 = null;
			int pStrSize0 = 0;
			if (fmt != null)
			{
				pStrSize0 = Utils.GetByteCountUTF8(fmt);
				if (pStrSize0 >= Utils.MaxStackallocSize)
				{
					pStr0 = Utils.Alloc<byte>(pStrSize0 + 1);
				}
				else
				{
					byte* pStrStack0 = stackalloc byte[pStrSize0 + 1];
					pStr0 = pStrStack0;
				}
				int pStrOffset0 = Utils.EncodeStringUTF8(fmt, pStr0, pStrSize0);
				pStr0[pStrOffset0] = 0;
			}
			AppendNative(self, pos, off, bg, fg, clamp ? (byte)1 : (byte)0, pStr0);
			if (pStrSize0 >= Utils.MaxStackallocSize)
			{
				Utils.Free(pStr0);
			}
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		public static void Append(ref ImPlotAnnotationCollection self, Vector2 pos, Vector2 off, uint bg, uint fg, bool clamp, ref byte fmt)
		{
			fixed (ImPlotAnnotationCollection* pself = &self)
			{
				fixed (byte* pfmt = &fmt)
				{
					AppendNative((ImPlotAnnotationCollection*)pself, pos, off, bg, fg, clamp ? (byte)1 : (byte)0, (byte*)pfmt);
				}
			}
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		public static void Append(ref ImPlotAnnotationCollection self, Vector2 pos, Vector2 off, uint bg, uint fg, bool clamp, ReadOnlySpan<byte> fmt)
		{
			fixed (ImPlotAnnotationCollection* pself = &self)
			{
				fixed (byte* pfmt = fmt)
				{
					AppendNative((ImPlotAnnotationCollection*)pself, pos, off, bg, fg, clamp ? (byte)1 : (byte)0, (byte*)pfmt);
				}
			}
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		public static void Append(ref ImPlotAnnotationCollection self, Vector2 pos, Vector2 off, uint bg, uint fg, bool clamp, string fmt)
		{
			fixed (ImPlotAnnotationCollection* pself = &self)
			{
				byte* pStr0 = null;
				int pStrSize0 = 0;
				if (fmt != null)
				{
					pStrSize0 = Utils.GetByteCountUTF8(fmt);
					if (pStrSize0 >= Utils.MaxStackallocSize)
					{
						pStr0 = Utils.Alloc<byte>(pStrSize0 + 1);
					}
					else
					{
						byte* pStrStack0 = stackalloc byte[pStrSize0 + 1];
						pStr0 = pStrStack0;
					}
					int pStrOffset0 = Utils.EncodeStringUTF8(fmt, pStr0, pStrSize0);
					pStr0[pStrOffset0] = 0;
				}
				AppendNative((ImPlotAnnotationCollection*)pself, pos, off, bg, fg, clamp ? (byte)1 : (byte)0, pStr0);
				if (pStrSize0 >= Utils.MaxStackallocSize)
				{
					Utils.Free(pStr0);
				}
			}
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		[MethodImpl(MethodImplOptions.AggressiveInlining)]
		internal static byte* GetTextNative(ImPlotAnnotationCollection* self, int idx)
		{
			#if NET5_0_OR_GREATER
			return ((delegate* unmanaged[Cdecl]<ImPlotAnnotationCollection*, int, byte*>)funcTable[495])(self, idx);
			#else
			return (byte*)((delegate* unmanaged[Cdecl]<nint, int, nint>)funcTable[495])((nint)self, idx);
			#endif
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		public static byte* GetText(ImPlotAnnotationCollectionPtr self, int idx)
		{
			byte* ret = GetTextNative(self, idx);
			return ret;
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		public static string GetTextS(ImPlotAnnotationCollectionPtr self, int idx)
		{
			string ret = Utils.DecodeStringUTF8(GetTextNative(self, idx));
			return ret;
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		public static byte* GetText(ref ImPlotAnnotationCollection self, int idx)
		{
			fixed (ImPlotAnnotationCollection* pself = &self)
			{
				byte* ret = GetTextNative((ImPlotAnnotationCollection*)pself, idx);
				return ret;
			}
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		public static string GetTextS(ref ImPlotAnnotationCollection self, int idx)
		{
			fixed (ImPlotAnnotationCollection* pself = &self)
			{
				string ret = Utils.DecodeStringUTF8(GetTextNative((ImPlotAnnotationCollection*)pself, idx));
				return ret;
			}
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		[MethodImpl(MethodImplOptions.AggressiveInlining)]
		internal static void ResetNative(ImPlotAnnotationCollection* self)
		{
			#if NET5_0_OR_GREATER
			((delegate* unmanaged[Cdecl]<ImPlotAnnotationCollection*, void>)funcTable[496])(self);
			#else
			((delegate* unmanaged[Cdecl]<nint, void>)funcTable[496])((nint)self);
			#endif
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		public static void Reset(ImPlotAnnotationCollectionPtr self)
		{
			ResetNative(self);
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		public static void Reset(ref ImPlotAnnotationCollection self)
		{
			fixed (ImPlotAnnotationCollection* pself = &self)
			{
				ResetNative((ImPlotAnnotationCollection*)pself);
			}
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		[MethodImpl(MethodImplOptions.AggressiveInlining)]
		internal static ImPlotTagCollection* ImPlotTagCollectionNative()
		{
			#if NET5_0_OR_GREATER
			return ((delegate* unmanaged[Cdecl]<ImPlotTagCollection*>)funcTable[497])();
			#else
			return (ImPlotTagCollection*)((delegate* unmanaged[Cdecl]<nint>)funcTable[497])();
			#endif
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		public static ImPlotTagCollectionPtr ImPlotTagCollection()
		{
			ImPlotTagCollectionPtr ret = ImPlotTagCollectionNative();
			return ret;
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		[MethodImpl(MethodImplOptions.AggressiveInlining)]
		internal static void DestroyNative(ImPlotTagCollection* self)
		{
			#if NET5_0_OR_GREATER
			((delegate* unmanaged[Cdecl]<ImPlotTagCollection*, void>)funcTable[498])(self);
			#else
			((delegate* unmanaged[Cdecl]<nint, void>)funcTable[498])((nint)self);
			#endif
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		public static void Destroy(ImPlotTagCollectionPtr self)
		{
			DestroyNative(self);
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		public static void Destroy(ref ImPlotTagCollection self)
		{
			fixed (ImPlotTagCollection* pself = &self)
			{
				DestroyNative((ImPlotTagCollection*)pself);
			}
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		[MethodImpl(MethodImplOptions.AggressiveInlining)]
		internal static void AppendVNative(ImPlotTagCollection* self, ImAxis axis, double value, uint bg, uint fg, byte* fmt, nuint args)
		{
			#if NET5_0_OR_GREATER
			((delegate* unmanaged[Cdecl]<ImPlotTagCollection*, ImAxis, double, uint, uint, byte*, nuint, void>)funcTable[499])(self, axis, value, bg, fg, fmt, args);
			#else
			((delegate* unmanaged[Cdecl]<nint, ImAxis, double, uint, uint, nint, nuint, void>)funcTable[499])((nint)self, axis, value, bg, fg, (nint)fmt, args);
			#endif
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		public static void AppendV(ImPlotTagCollectionPtr self, ImAxis axis, double value, uint bg, uint fg, byte* fmt, nuint args)
		{
			AppendVNative(self, axis, value, bg, fg, fmt, args);
		}
	}
}
